{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import path, stat, system\n",
    "from datetime import datetime,timedelta\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplc\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "print(\"Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Aggregate partial sums and object distributions over a range of forecast cases.\\nNOTE: All arguments listed below are REQUIRED, except for -diag\",\n",
    "                                 formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "                                 usage=\"aggregate_MODE_scores.py [-h] [options]\",\n",
    "                                 epilog=\"SECOND of three scripts necessary to perform and plot object-based verification scores using MODE.\")\n",
    "\n",
    "arg_dict = {\n",
    "    'model': 'RRFS_CONUS_3km',\n",
    "    'field': 'compref',\n",
    "    'dump_root': '/mnt/lfs4/BMC/amb-verif/RT_MODE/python_data',\n",
    "    'idate': '2022051800',\n",
    "    'edate': '2022070200',\n",
    "    'diag': 1\n",
    "}                                 \n",
    "\n",
    "args = argparse.Namespace(**arg_dict)\n",
    "                                 \n",
    "# Apply input arguments to global settings\n",
    "name = args.model\n",
    "field = args.field\n",
    "dump_dir = args.dump_root + '/' + name + '/' + field\n",
    "img_root = \"/lfs4/BMC/wrfruc/nickel/mode_img\"\n",
    "img_dir = \"{}/{}/{}/images/valid_time\".format(img_root,name,field)\n",
    "iyear = int(args.idate[:4])\n",
    "eyear = int(args.edate[:4])\n",
    "imonth = int(args.idate[4:6])\n",
    "emonth = int(args.edate[4:6])\n",
    "iday = int(args.idate[6:8])\n",
    "eday = int(args.edate[6:8])\n",
    "ihr = int(args.idate[8:10])\n",
    "ehr = int(args.edate[8:10])\n",
    "os.makedirs(img_dir, exist_ok = True)\n",
    "\n",
    "# Hard-coded constants/settings\n",
    "fcst_length = 3\n",
    "tod_start = 6\n",
    "T_start = 1\n",
    "delta_hr = 1 # distance between forecast initialization times\n",
    "if field == \"compref\":\n",
    "   accum_hr = \"00\"\n",
    "elif field == \"precip\":\n",
    "   accum_hr = \"06\"\n",
    "n_rad = 1\n",
    "n_thresh = 4\n",
    "match_int = 0.70 # threshold interest value to declare a match\n",
    "agg_vhr_start = [0,6,12,18,0,6,21]\n",
    "agg_vhr_end =   [5,11,17,23,23,17,3]\n",
    "dx = 3.0 # grid spacing\n",
    "match_int = 0.70 # threshold interest value to declare a match\n",
    "# create color scheme for multiple convolution radius and threshold testing\n",
    "centroid_FB_plot = True\n",
    "cmp = mplc.get_cmap('coolwarm')\n",
    "nq = np.linspace(0,1,n_rad*n_thresh+1)\n",
    "colors = cmp(nq)\n",
    "\n",
    "###################### END SETTINGS #######################################\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON RADIUS 1\n",
      "WORKING ON THRESHOLD 1\n",
      "WORKING ON TIME OF DAY 0600 UTC\n",
      "looping over all 01-hour forecasts starting at 05Z...\n",
      "looping over all 02-hour forecasts starting at 04Z...\n",
      "looping over all 03-hour forecasts starting at 03Z...\n",
      "There are a total of 3514 forecast objects and 1785 observation objects to evaluate over 39 cases at 0600 UTC\n",
      "There were 21 matched object pairs representing the shape of a single intense thunderstorm evaluated at 0600 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3475.0\n",
      "1779.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON TIME OF DAY 1800 UTC\n",
      "looping over all 01-hour forecasts starting at 17Z...\n",
      "looping over all 02-hour forecasts starting at 16Z...\n",
      "looping over all 03-hour forecasts starting at 15Z...\n",
      "There are a total of 5397 forecast objects and 2622 observation objects to evaluate over 44 cases at 1800 UTC\n",
      "There were 147 matched object pairs representing the shape of a single intense thunderstorm evaluated at 1800 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5336.0\n",
      "2589.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:825: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_mean_dist[d] = agg_dist_sum[d] / agg_dist_count[d]\n",
      "<ipython-input-3-eee9e0b684e7>:826: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_OTS[d] = agg_ots_sum[d,0] / agg_ots_sum[d,1]\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots of time-aggregated spatial frequency bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON THRESHOLD 2\n",
      "WORKING ON TIME OF DAY 0600 UTC\n",
      "looping over all 01-hour forecasts starting at 05Z...\n",
      "looping over all 02-hour forecasts starting at 04Z...\n",
      "looping over all 03-hour forecasts starting at 03Z...\n",
      "There are a total of 2789 forecast objects and 1467 observation objects to evaluate over 39 cases at 0600 UTC\n",
      "There were 70 matched object pairs representing the shape of a single intense thunderstorm evaluated at 0600 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2766.0\n",
      "1467.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON TIME OF DAY 1800 UTC\n",
      "looping over all 01-hour forecasts starting at 17Z...\n",
      "looping over all 02-hour forecasts starting at 16Z...\n",
      "looping over all 03-hour forecasts starting at 15Z...\n",
      "There are a total of 4261 forecast objects and 1914 observation objects to evaluate over 44 cases at 1800 UTC\n",
      "There were 353 matched object pairs representing the shape of a single intense thunderstorm evaluated at 1800 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4218.0\n",
      "1893.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:825: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_mean_dist[d] = agg_dist_sum[d] / agg_dist_count[d]\n",
      "<ipython-input-3-eee9e0b684e7>:826: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_OTS[d] = agg_ots_sum[d,0] / agg_ots_sum[d,1]\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots of time-aggregated spatial frequency bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON THRESHOLD 3\n",
      "WORKING ON TIME OF DAY 0600 UTC\n",
      "looping over all 01-hour forecasts starting at 05Z...\n",
      "looping over all 02-hour forecasts starting at 04Z...\n",
      "looping over all 03-hour forecasts starting at 03Z...\n",
      "There are a total of 2073 forecast objects and 1014 observation objects to evaluate over 39 cases at 0600 UTC\n",
      "There were 124 matched object pairs representing the shape of a single intense thunderstorm evaluated at 0600 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  bias_by_size = 1.0*f_hist / o_hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2062.0\n",
      "1014.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON TIME OF DAY 1800 UTC\n",
      "looping over all 01-hour forecasts starting at 17Z...\n",
      "looping over all 02-hour forecasts starting at 16Z...\n",
      "looping over all 03-hour forecasts starting at 15Z...\n",
      "There are a total of 3165 forecast objects and 1114 observation objects to evaluate over 44 cases at 1800 UTC\n",
      "There were 550 matched object pairs representing the shape of a single intense thunderstorm evaluated at 1800 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  bias_by_size = 1.0*f_hist / o_hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139.0\n",
      "1102.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:825: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_mean_dist[d] = agg_dist_sum[d] / agg_dist_count[d]\n",
      "<ipython-input-3-eee9e0b684e7>:826: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_OTS[d] = agg_ots_sum[d,0] / agg_ots_sum[d,1]\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots of time-aggregated spatial frequency bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON THRESHOLD 4\n",
      "WORKING ON TIME OF DAY 0600 UTC\n",
      "looping over all 01-hour forecasts starting at 05Z...\n",
      "looping over all 02-hour forecasts starting at 04Z...\n",
      "looping over all 03-hour forecasts starting at 03Z...\n",
      "There are a total of 1441 forecast objects and 525 observation objects to evaluate over 39 cases at 0600 UTC\n",
      "There were 264 matched object pairs representing the shape of a single intense thunderstorm evaluated at 0600 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  bias_by_size = 1.0*f_hist / o_hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435.0\n",
      "525.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON TIME OF DAY 1800 UTC\n",
      "looping over all 01-hour forecasts starting at 17Z...\n",
      "looping over all 02-hour forecasts starting at 16Z...\n",
      "looping over all 03-hour forecasts starting at 15Z...\n",
      "There are a total of 2170 forecast objects and 491 observation objects to evaluate over 44 cases at 1800 UTC\n",
      "There were 617 matched object pairs representing the shape of a single intense thunderstorm evaluated at 1800 UTC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:455: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  bias_by_size = 1.0*f_hist / o_hist\n",
      "<ipython-input-3-eee9e0b684e7>:455: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bias_by_size = 1.0*f_hist / o_hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154.0\n",
      "485.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:515: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:825: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_mean_dist[d] = agg_dist_sum[d] / agg_dist_count[d]\n",
      "<ipython-input-3-eee9e0b684e7>:826: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  agg_OTS[d] = agg_ots_sum[d,0] / agg_ots_sum[d,1]\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots of time-aggregated spatial frequency bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "<ipython-input-3-eee9e0b684e7>:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1483: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/contrib/miniconda3/4.5.12/envs/pygraf/lib/python3.8/site-packages/matplotlib/contour.py:1484: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    }
   ],
   "source": [
    "def calc_CRPS(F,O,data_bins):\n",
    "   delta = data_bins[1:] - data_bins[:-1]\n",
    "   f_hist,bins = np.histogram(F,bins=data_bins)\n",
    "   o_hist,bins = np.histogram(O,bins=data_bins)\n",
    "   f_hist = f_hist / float(len(F))\n",
    "   o_hist = o_hist / float(len(O))\n",
    "   score = np.sum(delta*(np.cumsum(f_hist) - np.cumsum(o_hist))**2)\n",
    "   return score\n",
    "\n",
    "def fmt(x, pos):\n",
    "    a, b = '{:.1e}'.format(x).split('e')\n",
    "    b = int(b)\n",
    "    return r'${} \\times 10^{{{}}}$'.format(a, b)\n",
    "\n",
    "end_time = datetime(year=eyear,month=emonth,day=eday,hour=ehr)\n",
    "\n",
    "# map projections\n",
    "# full CONUS\n",
    "if False:\n",
    "   clat = 39.0\n",
    "   clon = -95.0\n",
    "   proj_wid = 5.25e6\n",
    "   proj_hgt = 3.25e6\n",
    "   min_area = 500\n",
    "   res = 'h'\n",
    "   lbl_off_x = 30000\n",
    "   lbl_off_y = 20000\n",
    "   figsize = (12,8)\n",
    "else:\n",
    "# Eastern 2/3ds US\n",
    "   clat = 39.0\n",
    "   clon = -90.0\n",
    "   proj_wid = 3.05e6\n",
    "   proj_hgt = 2.45e6\n",
    "   min_area = 250\n",
    "   res = 'h'\n",
    "   lbl_off_y = 10000\n",
    "   lbl_off_x = 15000\n",
    "   figsize = (12,9.5)\n",
    "\n",
    "# set lat and lon bins for centroid binning\n",
    "lon_bins = np.arange(-110.0,-65.1,1.0)\n",
    "lat_bins = np.arange(25.0,51.1,1.0)\n",
    "res_label = \"1p0\"\n",
    "lats_2d,lons_2d = np.meshgrid(lat_bins,lon_bins)\n",
    "# set x-/y- centroid error bins [km...raw data is in m...need to convert]\n",
    "x_bins = np.arange(-150.0,150.1,10.0)\n",
    "y_bins = np.arange(-150.0,150.1,10.0)\n",
    "cy2d,cx2d = np.meshgrid(y_bins,x_bins)\n",
    "\n",
    "area_bins = np.array([144,200,300,400,500,600,800,1000,1250,1500,2000,2500,3000,4000,5000,10000,20000,50000])\n",
    "mass_bins = np.array([0.0,0.1,1,2,4,8,16,32,64,100,200,500,1000,1500,2000,3000,5000])\n",
    "if field == \"precip\":\n",
    "   pXX_bins = np.array([0,1,3,5,10,15,20,25,30,40,50,100])\n",
    "elif field == \"compref\":\n",
    "   pXX_bins = np.arange(20.,75.1,5.0)\n",
    "curvature_bins = np.arange(700.,3500.1,100.)\n",
    "\n",
    "for R in range(1,n_rad+1):\n",
    "   print(\"WORKING ON RADIUS {}\".format(R))\n",
    "   for T in range(T_start,n_thresh+1):\n",
    "      print(\"WORKING ON THRESHOLD {}\".format(T))\n",
    "\n",
    "      # to set color index in later plots\n",
    "      color_number = n_thresh*(R-1) + T - 1 # to force 0-base\n",
    "\n",
    "      # Output metrics as a function of time of day\n",
    "      # aggregated across all cases\n",
    "      num_fcst_objs = np.zeros(24,dtype=np.int)\n",
    "      num_obs_objs = np.zeros(num_fcst_objs.shape,dtype=np.int)\n",
    "      num_pairs = np.zeros(num_fcst_objs.shape,dtype=np.int)\n",
    "      OTS = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      MMI = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      total_pod = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      total_sr = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      total_far = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      total_csi = np.full(num_fcst_objs.shape,-999.,dtype=np.float)\n",
    "      mean_centroid_dist = np.full((24,5),-999.,dtype=np.float)\n",
    "      median_centroid_dist = np.full(mean_centroid_dist.shape,-999.,dtype=np.float)\n",
    "      std_centroid_dist = np.zeros(mean_centroid_dist.shape,dtype=np.float)\n",
    "      fbias = -999.\n",
    "\n",
    "      # All-24-hour aggregated object attribute distributions\n",
    "      all_f_area = np.empty(0,dtype=np.int)\n",
    "      all_f_aspect = np.empty(0,dtype=np.float)\n",
    "      all_f_complexity = np.empty(0,dtype=np.float)\n",
    "      all_f_pXX = np.empty(0,dtype=np.float)\n",
    "      all_f_mass = np.empty(0,dtype=np.float)\n",
    "      all_o_area = np.empty(0,dtype=np.int)\n",
    "      all_o_aspect = np.empty(0,dtype=np.float)\n",
    "      all_o_complexity = np.empty(0,dtype=np.float)\n",
    "      all_o_pXX = np.empty(0,dtype=np.float)\n",
    "      all_o_mass = np.empty(0,dtype=np.float)\n",
    "\n",
    "      # Based on this array dimensionality, aggregated scores cannot be plotted in this code and must instead be plotted in the \"plot_agg_MODE_scores.py\" script\n",
    "      # Final time-aggregated scores\n",
    "      agg_OTS = np.full((len(agg_vhr_start)),-999.,dtype=np.float)\n",
    "      agg_MMI = np.full(agg_OTS.shape,-999.,dtype=np.float)\n",
    "      agg_pod = np.full(agg_OTS.shape,-999.,dtype=np.float)\n",
    "      agg_far = np.full(agg_OTS.shape,-999.,dtype=np.float)\n",
    "      agg_sr = np.full(agg_OTS.shape,-999.,dtype=np.float)\n",
    "      agg_csi = np.full(agg_OTS.shape,-999.,dtype=np.float)\n",
    "      agg_mean_dist = np.full(agg_OTS.shape,-999.,dtype=np.float) # ONLY ALL MATCHED objects (not JUST STORMS)\n",
    "      agg_gen_dist = np.full(agg_OTS.shape,-999.,dtype=np.float) # for generalized distance\n",
    "      agg_fcst_count = np.zeros(agg_OTS.shape,dtype=np.int)\n",
    "      agg_obs_count = np.zeros(agg_OTS.shape,dtype=np.int)\n",
    "      agg_fbias = np.full(agg_OTS.shape,np.nan,dtype=np.float) # object count\n",
    "\n",
    "      # Time-aggregated score components\n",
    "      agg_ots_sum = np.zeros((len(agg_vhr_start),2),dtype=np.float)\n",
    "      # One agg_max_int array for each possible set of aggregated time periods\n",
    "      for d in range(0,len(agg_vhr_start)):\n",
    "         exec(\"agg_f_cent_lon_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "         exec(\"agg_f_cent_lat_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "         exec(\"agg_o_cent_lon_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "         exec(\"agg_o_cent_lat_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "         exec(\"agg_max_int_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "         exec(\"agg_gen_dist_{:02d} = np.empty(0,dtype=np.float)\".format(d))\n",
    "      agg_hit = np.zeros(len(agg_vhr_start),dtype=np.int)\n",
    "      agg_fa = np.zeros(len(agg_vhr_start),dtype=np.int)\n",
    "      agg_miss = np.zeros(len(agg_vhr_start),dtype=np.int)\n",
    "      agg_dist_sum = np.zeros(len(agg_vhr_start),dtype=np.float)\n",
    "      agg_dist_count = np.zeros(len(agg_vhr_start),dtype=np.int)\n",
    "\n",
    "      ff = 0 # ff will still correspond to time-of-day index\n",
    "      if T != T_start:\n",
    "         tod_start = 6\n",
    "      for tod in [6, 18]:\n",
    "         time_of_day = \"{:02d}\".format(tod)\n",
    "         print(\"WORKING ON TIME OF DAY {}00 UTC\".format(time_of_day))\n",
    "\n",
    "         ots_sum = np.zeros(2,dtype=np.float)\n",
    "         max_int_array = np.empty(0,dtype=np.float)\n",
    "\n",
    "         # initialize empty arrays for all-case distribution. Since we don't know the number of forecast and observation objects\n",
    "         # at the moment we first perform the data read, we will start with empty arrays and build them up as we go.\n",
    "         ### individual object qualities\n",
    "         f_cent_lat = np.empty(0,dtype=np.float)\n",
    "         f_cent_lon = np.empty(0,dtype=np.float)\n",
    "         f_angle = np.empty(0,dtype=np.float)\n",
    "         f_length = np.empty(0,dtype=np.float)\n",
    "         f_width = np.empty(0,dtype=np.float)\n",
    "         f_aspect = np.empty(0,dtype=np.float)\n",
    "         f_area = np.empty(0,dtype=np.float)\n",
    "         f_curvature = np.empty(0,dtype=np.float)\n",
    "         f_complexity = np.empty(0,dtype=np.float)\n",
    "         f_p10 = np.empty(0,dtype=np.float)\n",
    "         f_p25 = np.empty(0,dtype=np.float)\n",
    "         f_p50 = np.empty(0,dtype=np.float)\n",
    "         f_p75 = np.empty(0,dtype=np.float)\n",
    "         f_p90 = np.empty(0,dtype=np.float)\n",
    "         f_pXX = np.empty(0,dtype=np.float)\n",
    "         f_mass = np.empty(0,dtype=np.float)\n",
    "         o_cent_x = np.empty(0,dtype=np.float)\n",
    "         o_cent_y = np.empty(0,dtype=np.float)\n",
    "         o_cent_lat = np.empty(0,dtype=np.float)\n",
    "         o_cent_lon = np.empty(0,dtype=np.float)\n",
    "         o_angle = np.empty(0,dtype=np.float)\n",
    "         o_length = np.empty(0,dtype=np.float)\n",
    "         o_width = np.empty(0,dtype=np.float)\n",
    "         o_aspect = np.empty(0,dtype=np.float)\n",
    "         o_area = np.empty(0,dtype=np.float)\n",
    "         o_area_t = np.empty(0,dtype=np.float)\n",
    "         o_curvature = np.empty(0,dtype=np.float)\n",
    "         o_complexity = np.empty(0,dtype=np.float)\n",
    "         o_p10 = np.empty(0,dtype=np.float)\n",
    "         o_p25 = np.empty(0,dtype=np.float)\n",
    "         o_p50 = np.empty(0,dtype=np.float)\n",
    "         o_p75 = np.empty(0,dtype=np.float)\n",
    "         o_p90 = np.empty(0,dtype=np.float)\n",
    "         o_pXX = np.empty(0,dtype=np.float)\n",
    "         o_mass = np.empty(0,dtype=np.float)\n",
    "         # object pair attributes\n",
    "         pair_dcentroid = np.empty(0,dtype=np.float)\n",
    "         pair_dangle = np.empty(0,dtype=np.float)\n",
    "         pair_daspect = np.empty(0,dtype=np.float)\n",
    "         pair_area_ratio = np.empty(0,dtype=np.float)\n",
    "         pair_int_area = np.empty(0,dtype=np.float)\n",
    "         pair_union_area = np.empty(0,dtype=np.float)\n",
    "         pair_sym_diff_area = np.empty(0,dtype=np.float)\n",
    "         pair_consum_ratio = np.empty(0,dtype=np.float)\n",
    "         pair_curv_ratio = np.empty(0,dtype=np.float)\n",
    "         pair_complex_ratio = np.empty(0,dtype=np.float)\n",
    "         pair_pct_intense_ratio = np.empty(0,dtype=np.float)\n",
    "         pair_interest = np.empty(0,dtype=np.float)\n",
    "         # contingency table statistics\n",
    "         hit = 0\n",
    "         miss = 0\n",
    "         false_alarm = 0\n",
    "         n_matches = 0\n",
    "         storm_match_dist_array = np.empty(0,dtype=np.float)\n",
    "         all_match_dist_array = np.empty(0,dtype=np.float)\n",
    "         gen_match_dist_array = np.empty(0,dtype=np.float)\n",
    "         gen_x_error_match_dist = np.empty(0,dtype=np.float)\n",
    "         gen_y_error_match_dist = np.empty(0,dtype=np.float)\n",
    "\n",
    "         n_cases = 0\n",
    "         # Determine the number of forecast lengths to evaluate\n",
    "         if tod % delta_hr == 0:\n",
    "            N_fhr_check = 1 + (fcst_length/delta_hr)\n",
    "         else:\n",
    "            N_fhr_check = fcst_length/delta_hr\n",
    "         for n in range(1,int(N_fhr_check)+1):\n",
    "            # Finally, the magical formula that does this right!\n",
    "            fhr = (tod % delta_hr + (n-1)*delta_hr)\n",
    "            init_hr = (tod - fhr) % 24\n",
    "            lead = \"{:02d}\".format(fhr)\n",
    "            \n",
    "            # loop over all cases/forecast files starting at \"init_hr\" with forecast hour \"fhr\"\n",
    "            # time is the time at the start of each forecast case\n",
    "            if fhr > 0:\n",
    "                start_time = datetime(year=iyear,month=imonth,day=iday,hour=init_hr)\n",
    "                time = start_time\n",
    "                if args.diag >= 1:\n",
    "                   print(\"looping over all {:02d}-hour forecasts starting at {:02d}Z...\".format(fhr,init_hr))\n",
    "                while time <= end_time:\n",
    "                   cyear = str(time.year)\n",
    "                   cmonth = \"{:02d}\".format(time.month)\n",
    "                   cday = \"{:02d}\".format(time.day)\n",
    "                   chour = \"{:02d}\".format(time.hour)\n",
    "                   casedir = cyear + cmonth + cday + chour\n",
    "                   # set up the valid time\n",
    "                   vtime = time + timedelta(hours=fhr)\n",
    "                   vyear = str(vtime.year)\n",
    "                   vmonth = \"{:02d}\".format(vtime.month)\n",
    "                   vday = \"{:02d}\".format(vtime.day)\n",
    "                   vhour = \"{:02d}\".format(vtime.hour)\n",
    "\n",
    "                   if args.diag >= 2:\n",
    "                      print(\"WORKING ON FORECAST CASE {}{}{} {}Z\".format(cyear,cmonth,cday,chour))\n",
    "\n",
    "                   psum_filename = \"{}/partial_sums/{}/partial_sums_r{}t{}_{}_f{}.npz\".format(dump_dir,casedir,R,T,casedir,lead)\n",
    "                   attr_filename = \"{}/object_attributes/{}/attributes_r{}t{}_{}_f{}.npz\".format(dump_dir,casedir,R,T,casedir,lead)\n",
    "                   if path.isfile(psum_filename) and path.isfile(attr_filename):\n",
    "                      data_psum = np.load(psum_filename)\n",
    "                      data_attr = np.load(attr_filename)\n",
    "                      n_cases += 1\n",
    "                   else:\n",
    "                      if args.diag >= 2:\n",
    "                         print(\" partial sum file {} not found!\".format(psum_filename))\n",
    "                      # Increment time and move to next case\n",
    "                      time += timedelta(hours=24)\n",
    "                      continue\n",
    "\n",
    "                   # Construct all-case sum from partial sums\n",
    "                   ots_sum[0] += data_psum['ots_sum_numer']\n",
    "                   ots_sum[1] += data_psum['ots_sum_denom']\n",
    "                   num_fcst_objs[ff] += data_psum['n_f_objs']\n",
    "                   num_obs_objs[ff] += data_psum['n_o_objs']\n",
    "                   hit += data_psum['n_hit']\n",
    "                   miss += data_psum['n_miss']\n",
    "                   false_alarm += data_psum['n_fa']\n",
    "\n",
    "                   # Construct large arrays to make final calculations\n",
    "                   max_int_array = np.append(max_int_array,data_attr['max_interest'])\n",
    "                   #standard_MMI = data_attr['MMI_flag']\n",
    "                   standard_MMI = True\n",
    "                   all_match_dist_array = np.append(all_match_dist_array,data_attr['all_match_dist'])\n",
    "                   storm_match_dist_array = np.append(storm_match_dist_array,data_attr['storm_match_dist'])\n",
    "                   gen_match_dist_array = np.append(gen_match_dist_array,data_attr['gen_match_dist'])\n",
    "                   gen_x_error_match_dist = np.append(gen_x_error_match_dist,data_attr['gen_match_x_error'])\n",
    "                   gen_y_error_match_dist = np.append(gen_y_error_match_dist,data_attr['gen_match_y_error'])\n",
    "\n",
    "                   # Append storm attribute file arrays to all-case arrays\n",
    "                   f_cent_lat = np.append(f_cent_lat,data_attr['file_f_cent_lat'])\n",
    "                   f_cent_lon = np.append(f_cent_lon,data_attr['file_f_cent_lon'])\n",
    "                   f_angle = np.append(f_angle,data_attr['file_f_angle'])\n",
    "                   f_length = np.append(f_length,data_attr['file_f_length'])\n",
    "                   f_width = np.append(f_width,data_attr['file_f_width'])\n",
    "                   f_aspect = np.append(f_aspect,data_attr['file_f_aspect'])\n",
    "                   f_area = np.append(f_area,data_attr['file_f_area'])\n",
    "                   f_curvature = np.append(f_curvature,data_attr['file_f_curvature'])\n",
    "                   f_complexity = np.append(f_complexity,data_attr['file_f_complexity'])\n",
    "                   f_p10 = np.append(f_p10,data_attr['file_f_p10'])\n",
    "                   f_p25 = np.append(f_p25,data_attr['file_f_p25'])\n",
    "                   f_p50 = np.append(f_p50,data_attr['file_f_p50'])\n",
    "                   f_p75 = np.append(f_p75,data_attr['file_f_p75'])\n",
    "                   f_p90 = np.append(f_p90,data_attr['file_f_p90'])\n",
    "                   f_pXX = np.append(f_pXX,data_attr['file_f_pXX'])\n",
    "                   f_mass = np.append(f_mass,data_attr['file_f_mass'])\n",
    "                   o_cent_lat = np.append(o_cent_lat,data_attr['file_o_cent_lat'])\n",
    "                   o_cent_lon = np.append(o_cent_lon,data_attr['file_o_cent_lon'])\n",
    "                   o_angle = np.append(o_angle,data_attr['file_o_angle'])\n",
    "                   o_length = np.append(o_length,data_attr['file_o_length'])\n",
    "                   o_width = np.append(o_width,data_attr['file_o_width'])\n",
    "                   o_aspect = np.append(o_aspect,data_attr['file_o_aspect'])\n",
    "                   o_area = np.append(o_area,data_attr['file_o_area'])\n",
    "                   o_curvature = np.append(o_curvature,data_attr['file_o_curvature'])\n",
    "                   o_complexity = np.append(o_complexity,data_attr['file_o_complexity'])\n",
    "                   o_p10 = np.append(o_p10,data_attr['file_o_p10'])\n",
    "                   o_p25 = np.append(o_p25,data_attr['file_o_p25'])\n",
    "                   o_p50 = np.append(o_p50,data_attr['file_o_p50'])\n",
    "                   o_p75 = np.append(o_p75,data_attr['file_o_p75'])\n",
    "                   o_p90 = np.append(o_p90,data_attr['file_o_p90'])\n",
    "                   o_pXX = np.append(o_pXX,data_attr['file_o_pXX'])\n",
    "                   o_mass = np.append(o_mass,data_attr['file_o_mass'])\n",
    "                   pair_dcentroid = np.append(pair_dcentroid,data_attr['file_pair_dcentroid'])\n",
    "                   pair_dangle = np.append(pair_dangle,data_attr['file_pair_dangle'])\n",
    "                   pair_daspect = np.append(pair_daspect,data_attr['file_pair_daspect'])\n",
    "                   pair_area_ratio = np.append(pair_area_ratio,data_attr['file_pair_area_ratio'])\n",
    "                   pair_int_area = np.append(pair_int_area,data_attr['file_pair_int_area'])\n",
    "                   pair_union_area = np.append(pair_union_area,data_attr['file_pair_union_area'])\n",
    "                   pair_sym_diff_area = np.append(pair_sym_diff_area,data_attr['file_pair_sym_diff_area'])\n",
    "                   pair_consum_ratio = np.append(pair_consum_ratio,data_attr['file_pair_consum_ratio'])\n",
    "                   pair_curv_ratio = np.append(pair_curv_ratio,data_attr['file_pair_curv_ratio'])\n",
    "                   pair_complex_ratio = np.append(pair_complex_ratio,data_attr['file_pair_complex_ratio'])\n",
    "                   pair_pct_intense_ratio = np.append(pair_pct_intense_ratio,data_attr['file_pair_pct_intense_ratio'])\n",
    "                   pair_interest = np.append(pair_interest,data_attr['file_pair_interest'])\n",
    "\n",
    "               #    print(\"There were {} forecast objects, {} observation objects, and {} pairs to evaluate in this file\".format(n_f,n_o,n_pairs))\n",
    "\n",
    "                   time += timedelta(hours=24)\n",
    "\n",
    "            # END case loop (forecast init/cycle time)\n",
    "         # END loop through forecast-hours-to-check\n",
    "\n",
    "         num_fcst_objs[ff] = len(f_cent_lon)\n",
    "         num_obs_objs[ff] = len(o_cent_lon)\n",
    "         num_pairs[ff] = len(pair_dcentroid)\n",
    "\n",
    "         # Aggregate object attributes over all hours of the day\n",
    "         all_f_area = np.append(all_f_area,f_area)\n",
    "         all_f_aspect = np.append(all_f_aspect,f_aspect)\n",
    "         all_f_complexity = np.append(all_f_complexity,f_complexity)\n",
    "         all_f_pXX = np.append(all_f_pXX,f_pXX)\n",
    "         all_f_mass = np.append(all_f_mass,f_mass)\n",
    "         all_o_area = np.append(all_o_area,o_area)\n",
    "         all_o_aspect = np.append(all_o_aspect,o_aspect)\n",
    "         all_o_complexity = np.append(all_o_complexity,o_complexity)\n",
    "         all_o_pXX = np.append(all_o_pXX,o_pXX)\n",
    "         all_o_mass = np.append(all_o_mass,o_mass)\n",
    "\n",
    "         for d in range(0,len(agg_vhr_start)):\n",
    "            # Typical range for aggregation period vs. aggregation period spanning 00Z\n",
    "            if ((agg_vhr_start[d] < agg_vhr_end[d]) and (tod >= agg_vhr_start[d] and tod <= agg_vhr_end[d])) \\\n",
    "            or \\\n",
    "            ((agg_vhr_start[d] > agg_vhr_end[d]) and (tod >= agg_vhr_start[d] or tod <= agg_vhr_end[d])):\n",
    "               exec(\"agg_f_cent_lon_{:02d} = np.append(agg_f_cent_lon_{:02d},f_cent_lon)\".format(d,d))\n",
    "               exec(\"agg_f_cent_lat_{:02d} = np.append(agg_f_cent_lat_{:02d},f_cent_lat)\".format(d,d))\n",
    "               exec(\"agg_o_cent_lon_{:02d} = np.append(agg_o_cent_lon_{:02d},o_cent_lon)\".format(d,d))\n",
    "               exec(\"agg_o_cent_lat_{:02d} = np.append(agg_o_cent_lat_{:02d},o_cent_lat)\".format(d,d))\n",
    "               exec(\"agg_gen_dist_{:02d} = np.append(agg_gen_dist_{:02d},gen_match_dist_array)\".format(d,d))\n",
    "\n",
    "         if args.diag >= 1:\n",
    "            print(\"There are a total of {} forecast objects and {} observation objects to evaluate over {} cases at {:02d}00 UTC\".format(num_fcst_objs[ff],num_obs_objs[ff],n_cases,tod))\n",
    "            print(\"There were {} matched object pairs representing the shape of a single intense thunderstorm evaluated at {:02d}00 UTC\".format(len(storm_match_dist_array),tod))\n",
    "\n",
    "         if len(storm_match_dist_array) > 0:\n",
    "            mean_centroid_dist[ff,0] = np.mean(storm_match_dist_array)\n",
    "            median_centroid_dist[ff,0] = np.median(storm_match_dist_array)\n",
    "            std_centroid_dist[ff,0] = np.std(storm_match_dist_array)\n",
    "         if len(all_match_dist_array) > 0:\n",
    "            mean_centroid_dist[ff,1] = np.mean(all_match_dist_array)\n",
    "            median_centroid_dist[ff,1] = np.median(all_match_dist_array)\n",
    "            std_centroid_dist[ff,1] = np.std(all_match_dist_array)\n",
    "         if len(gen_match_dist_array) > 0:\n",
    "            mean_centroid_dist[ff,2] = np.mean(gen_match_dist_array)\n",
    "            median_centroid_dist[ff,2] = np.median(gen_match_dist_array)\n",
    "            std_centroid_dist[ff,2] = np.std(gen_match_dist_array)\n",
    "\n",
    "         # Add time-aggregated score components to arrays\n",
    "         # (The final calculation of time-aggregated scores must occur outside of the forecast-hour loop...so...in other words...outside of THIS loop)\n",
    "         for d in range(0,len(agg_vhr_start)):\n",
    "            # Typical range for aggregation period vs. aggregation period spanning 00Z\n",
    "            if ((agg_vhr_start[d] < agg_vhr_end[d]) and (tod >= agg_vhr_start[d] and tod <= agg_vhr_end[d])) \\\n",
    "            or \\\n",
    "            ((agg_vhr_start[d] > agg_vhr_end[d]) and (tod >= agg_vhr_start[d] or tod <= agg_vhr_end[d])):\n",
    "               agg_ots_sum[d,0] += ots_sum[0]\n",
    "               agg_ots_sum[d,1] += ots_sum[1]\n",
    "               exec(\"agg_max_int_{:02d} = np.append(agg_max_int_{:02d},max_int_array)\".format(d,d))\n",
    "               exec(\"agg_gen_dist_{:02d} = np.append(agg_gen_dist_{:02d},gen_match_dist_array)\".format(d,d))\n",
    "               agg_dist_sum[d] += np.sum(all_match_dist_array)\n",
    "               agg_dist_count[d] += len(all_match_dist_array)\n",
    "               agg_hit[d] += hit\n",
    "               agg_miss[d] += miss\n",
    "               agg_fa[d] += false_alarm\n",
    "               agg_fcst_count[d] += num_fcst_objs[ff]\n",
    "               agg_obs_count[d] += num_obs_objs[ff]\n",
    "         for d in range(0,len(agg_vhr_start)):\n",
    "            exec(\"agg_gen_dist[{}] = np.mean(agg_gen_dist_{:02d})\".format(d,d))\n",
    "            if agg_obs_count[d] > 0:\n",
    "               agg_fbias[d] = float(agg_fcst_count[d]) / agg_obs_count[d]\n",
    "\n",
    "         if num_fcst_objs[ff] > 0 and num_obs_objs[ff] > 0:\n",
    "\n",
    "            if hit + miss > 0:\n",
    "               total_pod[ff] = float(hit) / (hit + miss)\n",
    "            if hit + false_alarm > 0:\n",
    "               total_sr[ff] = float(hit) / (hit + false_alarm)\n",
    "               total_far[ff] = float(false_alarm) / (hit + false_alarm)\n",
    "            if hit + miss + false_alarm > 0:\n",
    "               total_csi[ff] = float(hit) / (hit + miss + false_alarm)\n",
    "\n",
    "            OTS[ff] = ots_sum[0] / ots_sum[1]\n",
    "            MMI[ff] = np.median(max_int_array)\n",
    "\n",
    "            # Calculate object attribute distribution CRPSs\n",
    "            cent_lon_crps = calc_CRPS(f_cent_lon,o_cent_lon,np.arange(-108.,-75.1,0.1))\n",
    "            cent_lat_crps = calc_CRPS(f_cent_lat,o_cent_lat,np.arange(25.0,51.1,0.1))\n",
    "            area_crps = calc_CRPS(f_area,o_area,area_bins)\n",
    "            length_crps = calc_CRPS(f_length,o_length,np.arange(2.0,751.0,5.0))\n",
    "            width_crps = calc_CRPS(f_width,o_width,np.arange(1,301,1.0))\n",
    "            aspect_crps = calc_CRPS(f_aspect,o_aspect,np.arange(0.0,1.01,0.01))\n",
    "            complex_crps = calc_CRPS(f_complexity,o_complexity,np.arange(0.0,1.01,0.01))\n",
    "            pXX_crps = calc_CRPS(f_pXX,o_pXX,pXX_bins)\n",
    "            curv_crps = calc_CRPS(f_curvature,o_curvature,np.arange(0,3001,10))\n",
    "\n",
    "            if False:\n",
    "               # What is the typical area of objects with a given curvature?\n",
    "               curvature_bins = np.arange(700.,3500.1,100.)\n",
    "               curvature_area_sum = np.zeros_like(curvature_bins,dtype=np.float)\n",
    "               curvature_num = np.zeros_like(curvature_bins,dtype=np.int)\n",
    "               mean_area_curv = np.zeros_like(curvature_bins,dtype=np.float)\n",
    "               curvature_ar_sum = np.zeros_like(curvature_bins,dtype=np.float)\n",
    "               mean_AR_curv = np.zeros_like(curvature_bins,dtype=np.float)\n",
    "               for a in range(0,num_fcst_objs[ff]):\n",
    "                  for b in range(0,len(curvature_bins)-1):\n",
    "                     if f_curvature[a] > curvature_bins[b] and f_curvature[a] <= curvature_bins[b+1]:\n",
    "                        curvature_area_sum[b] += f_area[a]\n",
    "                        curvature_num[b] += 1\n",
    "                        curvature_ar_sum[b] += f_aspect[a]\n",
    "                        break\n",
    "               mean_area_curv = curvature_area_sum / curvature_num\n",
    "               mean_AR_curv = curvature_ar_sum / curvature_num\n",
    "               f = plt.figure(figsize=(5,5))\n",
    "               ax1 = f.add_axes([0.125,0.1,0.775,0.88])\n",
    "               ax1.set_xlim(curvature_bins[0],curvature_bins[-1])\n",
    "               ax1.set_xticks(curvature_bins[::2])\n",
    "               ax1.set_xlabel('Curvature value',fontsize=9)\n",
    "               ax2 = plt.twinx(ax1)\n",
    "               h1 = ax1.plot(0.5*(curvature_bins[:-1] + curvature_bins[1:]),mean_area_curv[:-1],'r-x',linewidth=2,label=\"area\")\n",
    "               h2 = ax2.plot(0.5*(curvature_bins[:-1] + curvature_bins[1:]),mean_AR_curv[:-1],'b-x',linewidth=2,label=\"aspect ratio\")\n",
    "               for a in range(0,len(curvature_bins)-1):\n",
    "                  if curvature_num[a] > 0:\n",
    "                     ax1.text(0.5*(curvature_bins[a] + curvature_bins[a+1]),mean_area_curv[a]+25,\"{:4d}\".format(curvature_num[a]),ha='center',va='bottom',fontsize=6,fontweight=200,rotation=45)\n",
    "               ax1.grid(linestyle=\":\",color=\"0.75\")\n",
    "               ax2.set_xlim(curvature_bins[0],curvature_bins[-1])\n",
    "               ax2.set_ylim(0,1)\n",
    "               ax2.set_yticks(np.arange(0.,1.01,0.1))\n",
    "               ax2.set_ylabel(\"aspect ratio\",fontsize=9)\n",
    "               ax1.set_ylabel(r\"object area [$km^2$]\",fontsize=9)\n",
    "               ax1.tick_params(axis='both',labelsize=6)\n",
    "               ax2.tick_params(axis='y',labelsize=6)\n",
    "               lns = h1 + h2\n",
    "               lbls = [l.get_label() for l in lns]\n",
    "               ax1.legend(lns,lbls,loc=0,fontsize=8)\n",
    "               image_file = \"{}/{}_curvature_parameters_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               f.savefig(image_file,dpi=120)\n",
    "               f.close()\n",
    "\n",
    "            if True:\n",
    "               # Determine object count bias as a function of object size\n",
    "               f_hist,bin = np.histogram(dx**2*f_area,bins=area_bins)\n",
    "               o_hist,bin = np.histogram(dx**2*o_area,bins=area_bins)\n",
    "               bias_by_size = 1.0*f_hist / o_hist\n",
    "               # Also corroborate frequency (coverage) bias from MATS by calculating total area\n",
    "               fbias = np.sum(f_area) / np.sum(o_area)\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.7,right=0.95)   #top=0.98\n",
    "               plt.semilogx(0.5*(bin[:-1]+bin[1:]),bias_by_size,'k-x',linewidth=1,label=name)\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               if T <= 2:\n",
    "                  plt.ylim(0.5,2.25)\n",
    "               else:\n",
    "                  plt.ylim(0.9,30)\n",
    "                  plt.yscale('log')\n",
    "               plt.title(\"{}Z MODE Object Bias by Size \\n 18 May 2022 - 02 July 2022\".format(time_of_day), fontsize = 12)\n",
    "               plt.xlabel(r\"Object Area [km$^{2}$]\",size=9)\n",
    "               plt.ylabel(\"Object Count Bias (F/O)\",size=9)\n",
    "               plt.tick_params(axis='both',labelsize=8)\n",
    "               plt.axvspan(0, 1000, alpha=0.5, color='lightgreen')\n",
    "               plt.legend(loc=1,prop={'size':9})\n",
    "               image_file = \"{}/{}_object_bias_by_size_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "            if True:\n",
    "               # map of east-west and south-north components of centroid error\n",
    "               plt.figure(figsize=(5.5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.80,right=0.875)\n",
    "               centroid_error_hist2d,binx,biny = np.histogram2d(gen_x_error_match_dist/1000.,gen_y_error_match_dist/1000.,bins=[x_bins,y_bins]) # division is to convert from m to km\n",
    "               hist = centroid_error_hist2d / len(gen_match_dist_array)\n",
    "               clevs = [1e-5,1e-4,2.5e-4,5e-4,7.5e-4,1e-3,2.5e-3,5e-3,7.5e-3,1e-2,2.5e-2,5e-2,7.5e-2,1e-1,2e-1]\n",
    "               ccs = mplc.get_cmap('BuPu',len(clevs))\n",
    "               plt.contourf(0.5*(cx2d[:-1,:-1]+cx2d[1:,1:]),0.5*(cy2d[:-1,:-1]+cy2d[1:,1:]),hist,clevs,colors=ccs(range(len(clevs))),extend='both')\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlim(x_bins[0],x_bins[-1])\n",
    "               plt.ylim(y_bins[0],y_bins[-1])\n",
    "               plt.xlabel(\"West-East Centroid Error [km]\",size= 9)\n",
    "               plt.ylabel(\"South-North Centroid Error [km]\",size= 9)\n",
    "               plt.tick_params(axis='both',labelsize=8)\n",
    "               plt.title(\"{}Z MODE Centroid Error\".format(time_of_day), fontsize = 12)\n",
    "               cb = plt.colorbar(orientation='vertical',fraction=0.05,aspect=20,pad=0.03,shrink=0.75,extend='max',format=ticker.FuncFormatter(fmt))\n",
    "               cb.set_ticks(clevs)\n",
    "               cb.set_label(\"relative frequency\",fontsize=10)\n",
    "               cb.ax.tick_params(labelsize=6)\n",
    "               plt.plot(np.nanmean(gen_x_error_match_dist)/1000.,np.nanmean(gen_y_error_match_dist)/1000.,'xk',ms=6,mew=2,label=\"mean error location\")\n",
    "               plt.plot(np.nanmedian(gen_x_error_match_dist)/1000.,np.nanmedian(gen_y_error_match_dist)/1000.,'ok',ms=6,mew=2,label=\"median error location\")\n",
    "               plt.legend(loc='upper right',prop={'size':8})\n",
    "               image_file = \"{}/{}_object_centroid_error_map_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "            if True:\n",
    "               # Projected map plots of object centroids\n",
    "               # We will keep this code so that any of the following three types of plots can be made just by commenting or setting flags (rather than replacing the code altogether)\n",
    "               # - forecast-object centroid density\n",
    "               # - observation-object centroid density\n",
    "               # - frequency bias of object centroid density\n",
    "               f_hist2d,binx,biny = np.histogram2d(f_cent_lon,f_cent_lat,bins=[lon_bins,lat_bins])\n",
    "               o_hist2d,binx,biny = np.histogram2d(o_cent_lon,o_cent_lat,bins=[lon_bins,lat_bins])\n",
    "               print(np.sum(f_hist2d))\n",
    "               print(np.sum(o_hist2d))\n",
    "               if centroid_FB_plot:\n",
    "                fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
    "               else:\n",
    "                hist2d = f_hist2d / (1.0*num_fcst_objs[ff])\n",
    "                #hist2d = o_hist2d / (1.0*num_obs_objs[ff])\n",
    "                hist_max = 10**np.ceil(np.log10(np.amax(hist2d)))\n",
    "               fig = plt.figure(figsize=figsize)\n",
    "               ax = plt.subplots_adjust(left=0.01,right=0.95,bottom=0.05,top=0.97)\n",
    "               m = Basemap(projection='lcc',width=proj_wid,height=proj_hgt,lat_0=clat,lon_0=clon,lat_1=38.5,resolution=res,area_thresh=min_area)\n",
    "               m.drawlsmask(land_color='0.9',ocean_color='powderblue')\n",
    "               m.drawcountries(linewidth=1,color='0.1')\n",
    "               if True:\n",
    "                  m.drawcoastlines(linewidth=0.5,color='0.4')\n",
    "               else:\n",
    "                  m.drawcounties(linewidth=0.5,color='0.6',linestyle='-')\n",
    "               m.drawstates(linewidth=0.5,color='0.5')\n",
    "               m.drawmapboundary(color=[0.25,0.01,0.02],linewidth=3)\n",
    "               m.drawmeridians(np.arange(-130.0,-50.1,5.0),linewidth=0.1,labels=[0,0,0,1],labelstyle='E/W',yoffset=lbl_off_y,fontsize=8,dashes=[2,2])\n",
    "               m.drawparallels(np.arange(20.0,55.1,5.0),linewidth=0.1,labels=[0,1,0,0],labelstyle='E/W',xoffset=lbl_off_x,fontsize=8,dashes=[2,2])\n",
    "               x2d,y2d = m(lons_2d,lats_2d)\n",
    "               # Frequency bias plot\n",
    "               if centroid_FB_plot:\n",
    "                fb_clevs_low = np.array([0,0.25,0.5,0.75,0.9])\n",
    "                if T <= 2:\n",
    "                 fb_clevs_high = np.array([1.1,1.25,1.5,2,2.5,3,3.5,4])\n",
    "                elif T == 3:\n",
    "                 fb_clevs_high = np.array([1.1,1.25,1.5,2,2.5,3,3.5,4,5])\n",
    "                elif T >= 4:\n",
    "                 fb_clevs_high = np.array([1.1,1.25,1.5,2,2.5,3,3.5,4,5,7.5])\n",
    "                fb_clevs = np.append(fb_clevs_low,fb_clevs_high)\n",
    "                cm_low = mplc.get_cmap('Oranges_r',len(fb_clevs_low))\n",
    "                cm_high = mplc.get_cmap('Purples',len(fb_clevs_high))\n",
    "                cmap = np.vstack((cm_low(np.linspace(0,1,len(fb_clevs_low)-1)),np.array([0.9,1.0,0.9,1.0]),cm_high(np.linspace(0,1,len(fb_clevs_high)))))\n",
    "                final_colors = ListedColormap(cmap)\n",
    "                norm = BoundaryNorm(boundaries=fb_clevs,ncolors=len(fb_clevs),clip=True)\n",
    "              #  plt.pcolormesh(x2d[:-1,:-1],y2d[:-1,:-1],fbias_hist2d,norm=norm,cmap=final_colors)\n",
    "                plt.contourf(x2d[:-1,:-1],y2d[:-1,:-1],fbias_hist2d,levels=fb_clevs,colors=cmap,extend='max')\n",
    "                cb = plt.colorbar(orientation='horizontal',fraction=0.05,aspect=50,pad=0.03,shrink=0.5,extend='max')\n",
    "                cb.set_ticks(fb_clevs) # Frequency bias plot\n",
    "                cb.set_label(r'Frequency bias ($N_f / N_o$)',fontsize=10)\n",
    "                image_file = \"{}/{}_centroid_fbias_heatmap_r{}t{}_{:02d}Z_{}.png\".format(img_dir,name,R,T,tod,res_label)\n",
    "               else:\n",
    "                # Linear color scaling\n",
    "               # plt.pcolormesh(x2d[:-1,:-1],y2d[:-1,:-1],hist2d,vmin=1,vmax=5000),cmap=mplc.get_cmap('PuRd'))\n",
    "                # Logarithmic color scaling\n",
    "                plt.pcolormesh(x2d[:-1,:-1],y2d[:-1,:-1],hist2d,norm=matplotlib.colors.LogNorm(vmin=1e-4,vmax=0.01),cmap=mplc.get_cmap('PuRd'))\n",
    "                cb = plt.colorbar(orientation='horizontal',fraction=0.05,aspect=50,pad=0.03,shrink=0.5,extend='both')\n",
    "                cb.set_ticks([1e-4,5e-4,1e-3,5e-3,0.01,0.05,0.1]) # For log-based normalization of this plot\n",
    "                #cb.set_ticks([1,5,10,25,50,75,100,250,500,750,1000,5000])  # For linear scaling of this plot\n",
    "                cb.set_label(\"relative frequency\",fontsize=10)\n",
    "                image_file = \"{}/{}_centroid_heatmap_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               cb.ax.tick_params(labelsize=8)\n",
    "               fig.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "            ### Object attribute distributions\n",
    "            if True:\n",
    "               # Object centroid distribution\n",
    "               plt.figure(figsize=(9,5))\n",
    "               plt.subplots_adjust(left=0.075,bottom=0.075,top=0.98,right=0.98,wspace=0.2)\n",
    "               plt.subplot(1,2,1)\n",
    "               f_hist,bin = np.histogram(f_cent_lon,bins=np.arange(-107.5,-79.51,1.0))\n",
    "               o_hist,bin = np.histogram(o_cent_lon,bins=np.arange(-107.5,-79.51,1.0))\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),align='center',width=1.0,color='red',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),align='center',width=1.0,color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Object centroid longitude (deg.)\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               plt.legend(loc=1,prop={'size':8})\n",
    "               mu_f = np.mean(f_cent_lon)\n",
    "               mu_o = np.mean(o_cent_lon)\n",
    "               std_f = np.std(f_cent_lon)\n",
    "               std_o = np.std(o_cent_lon)\n",
    "               med_f = np.median(f_cent_lon)\n",
    "               med_o = np.median(o_cent_lon)\n",
    "               plt.figtext(0.10,0.83,r\"$\\mu_f$={:5.1f};  $\\mu_o$={:5.1f}\".format(mu_f,mu_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.10,0.78,r\"median$_f$={:5.1f};  median$_o$={:5.1f}\".format(med_f,med_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.10,0.73,r\"$\\sigma_f$={:4.1f};  $\\sigma_o$={:4.1f}\".format(std_f,std_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.10,0.68,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.10,0.63,\"CRPS={:5.3f}\".format(cent_lon_crps),ha='left',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               plt.subplot(1,2,2)\n",
    "               f_hist,bin = np.histogram(f_cent_lat,bins=np.arange(27.5,49.51,1.0))\n",
    "               o_hist,bin = np.histogram(o_cent_lat,bins=np.arange(27.5,49.51,1.0))\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),align='center',width=1.0,color='red',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),align='center',width=1.0,color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Object centroid latitude (deg.)\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               mu_f = np.mean(f_cent_lat)\n",
    "               mu_o = np.mean(o_cent_lat)\n",
    "               std_f = np.std(f_cent_lat)\n",
    "               std_o = np.std(o_cent_lat)\n",
    "               med_f = np.median(f_cent_lat)\n",
    "               med_o = np.median(o_cent_lat)\n",
    "               plt.figtext(0.97,0.96,r\"$\\mu_f$={:4.1f};  $\\mu_o$={:4.1f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.91,r\"median$_f$={:4.1f};  median$_o$={:4.1f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.86,r\"$\\sigma_f$={:4.1f};  $\\sigma_o$={:4.1f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.81,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.76,\"CRPS={:5.3f}\".format(cent_lat_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               image_file = \"{}/{}_object_centroid_loc_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "               # area\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.95)\n",
    "               f_hist,bin = np.histogram(dx**2*f_area,bins=[144,180,270,360,450,540,630,720,810,900,1000,1200,1400,1600,1800,2000])\n",
    "               o_hist,bin = np.histogram(dx**2*o_area,bins=[144,180,270,360,450,540,630,720,810,900,1000,1200,1400,1600,1800,2000])\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(r\"Object area [km$^{2}$]\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               plt.legend(loc=1,prop={'size':8})\n",
    "               mu_f = dx**2*np.mean(f_area)\n",
    "               mu_o = dx**2*np.mean(o_area)\n",
    "               std_f = np.std(dx**2*f_area)\n",
    "               std_o = np.std(dx**2*o_area)\n",
    "               med_f = dx**2*np.median(f_area)\n",
    "               med_o = dx**2*np.median(o_area)\n",
    "               plt.figtext(0.93,0.83,r\"$\\mu_f$={:4.0f};  $\\mu_o$={:4.0f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.78,r\"median$_f$={:4.0f};  median$_o$={:4.0f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.73,r\"$\\sigma_f$={:4.0f};  $\\sigma_o$={:4.0f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.68,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.63,\"CRPS={:5.3f}\".format(area_crps),ha='right',va='top',fontweight='bold',fontsize=9,bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               image_file = \"{}/{}_object_area_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "               # length and width\n",
    "               plt.figure(figsize=(9,5))\n",
    "               plt.subplots_adjust(left=0.075,bottom=0.075,top=0.98,right=0.98,wspace=0.2)\n",
    "               plt.subplot(1,2,1)\n",
    "               f_hist,bin = np.histogram(dx*f_length,bins=[6,25,50,75,100,125,150,175,200,250,300,400,500,600,750,1000])\n",
    "               o_hist,bin = np.histogram(dx*o_length,bins=[6,25,50,75,100,125,150,175,200,250,300,400,500,600,750,1000])\n",
    "               plt.semilogy(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),'s-r',linewidth=2,label=name)\n",
    "               plt.semilogy(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),'s-k',linewidth=2,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Object length [km]\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               plt.legend(loc=1,prop={'size':8})\n",
    "               mu_f = dx*np.mean(f_length)\n",
    "               mu_o = dx*np.mean(o_length)\n",
    "               std_f = np.std(dx*f_length)\n",
    "               std_o = np.std(dx*o_length)\n",
    "               med_f = dx*np.median(f_length)\n",
    "               med_o = dx*np.median(o_length)\n",
    "               plt.figtext(0.48,0.83,r\"$\\mu_f$={:4.0f};  $\\mu_o$={:4.0f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.48,0.78,r\"median$_f$={:4.0f};  median$_o$={:4.0f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.48,0.73,r\"$\\sigma_f$={:4.0f};  $\\sigma_o$={:4.0f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.48,0.68,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.48,0.63,\"CRPS={:5.3f}\".format(length_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               plt.subplot(1,2,2)\n",
    "               f_hist,bin = np.histogram(dx*f_width,bins=[6,20,30,40,50,60,75,100,125,150,175,200,250,300])\n",
    "               o_hist,bin = np.histogram(dx*o_width,bins=[6,20,30,40,50,60,75,100,125,150,175,200,250,300])\n",
    "               plt.semilogy(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),'s-r',linewidth=2,label=name)\n",
    "               plt.semilogy(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),'s-k',linewidth=2,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Object width [km]\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               mu_f = dx*np.mean(f_width)\n",
    "               mu_o = dx*np.mean(o_width)\n",
    "               std_f = np.std(dx*f_width)\n",
    "               std_o = np.std(dx*o_width)\n",
    "               med_f = dx*np.median(f_width)\n",
    "               med_o = dx*np.median(o_width)\n",
    "               plt.figtext(0.97,0.96,r\"$\\mu_f$={:3.0f};  $\\mu_o$={:3.0f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.91,r\"median$_f$={:3.0f};  median$_o$={:3.0f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.86,r\"$\\sigma_f$={:3.0f};  $\\sigma_o$={:3.0f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.81,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.76,\"CRPS={:5.3f}\".format(width_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               image_file = \"{}/{}_object_wid_len_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "               # aspect ratio\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.98)\n",
    "               f_hist,bin=np.histogram(f_aspect,bins=np.arange(0.0,1.01,0.1))\n",
    "               o_hist,bin=np.histogram(o_aspect,bins=np.arange(0.0,1.01,0.1))\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlim(0,1)\n",
    "               plt.xlabel(\"Object aspect ratio [width/length]\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               plt.legend(loc=1,prop={'size':8})\n",
    "               mu_f = np.mean(f_aspect)\n",
    "               mu_o = np.mean(o_aspect)\n",
    "               std_f = np.std(f_aspect)\n",
    "               std_o = np.std(o_aspect)\n",
    "               med_f = np.median(f_aspect)\n",
    "               med_o = np.median(o_aspect)\n",
    "               plt.figtext(0.14,0.97,r\"$\\mu_f$={:5.3f};  $\\mu_o$={:5.3f}\".format(mu_f,mu_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.14,0.92,r\"median$_f$={:5.3f};  median$_o$={:5.3f}\".format(med_f,med_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.14,0.87,r\"$\\sigma_f$={:5.3f};  $\\sigma_o$={:5.3f}\".format(std_f,std_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.14,0.82,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.14,0.77,\"CRPS={:5.3f}\".format(aspect_crps),ha='left',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               image_file = \"{}/{}_object_aspect_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "               # Complexity\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.98)\n",
    "               f_hist,bin=np.histogram(f_complexity,bins=np.arange(0.0,1.01,0.1))\n",
    "               o_hist,bin=np.histogram(o_complexity,bins=np.arange(0.0,1.01,0.1))\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlim(0,1)\n",
    "               plt.xlabel(\"Object complexity [-]\",size=8)\n",
    "               plt.ylabel(\"relative frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=6)\n",
    "               plt.legend(loc=1,prop={'size':8})\n",
    "               mu_f = np.mean(f_complexity)\n",
    "               mu_o = np.mean(o_complexity)\n",
    "               std_f = np.std(f_complexity)\n",
    "               std_o = np.std(o_complexity)\n",
    "               med_f = np.median(f_complexity)\n",
    "               med_o = np.median(o_complexity)\n",
    "               plt.figtext(0.97,0.83,r\"$\\mu_f$={:5.3f};  $\\mu_o$={:5.3f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.78,r\"median$_f$={:5.3f};  median$_o$={:5.3f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.73,r\"$\\sigma_f$={:5.3f};  $\\sigma_o$={:5.3f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.68,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.97,0.63,\"CRPS={:5.3f}\".format(complex_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               image_file = \"{}/{}_object_complex_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "               # Intensity percentile values\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,bottom=0.1,top=0.85,right=0.98)\n",
    "               if True in np.isnan(f_pXX):\n",
    "                print(\"Yeah, there are NaNs in f_pXX\")\n",
    "               f_hist,bin=np.histogram(f_pXX,bins=np.arange(25.0,70.1,5.0))\n",
    "               o_hist,bin=np.histogram(o_pXX,bins=np.arange(25.0,70.1,5.0))\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(num_fcst_objs[ff]),width=bin[1:]-bin[:-1],align='center',color='lightsteelblue',edgecolor='white',linewidth=1,label=name)\n",
    "               plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(num_obs_objs[ff]),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Object 95th percentile Value\",size=8)\n",
    "               plt.ylabel(\"Relative Frequency\",size=8)\n",
    "               plt.tick_params(axis='both',labelsize=7)\n",
    "               plt.legend(loc=7,prop={'size':8})\n",
    "               mu_f = np.mean(f_pXX)\n",
    "               mu_o = np.mean(o_pXX)\n",
    "               std_f = np.std(f_pXX)\n",
    "               std_o = np.std(o_pXX)\n",
    "               med_f = np.median(f_pXX)\n",
    "               med_o = np.median(o_pXX)\n",
    "               plt.figtext(0.95,0.80,r\"$\\mu_f$={:4.1f};  $\\mu_o$={:4.1f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=8,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.95,0.75,r\"median$_f$={:4.1f};  median$_o$={:4.1f}\".format(med_f,med_o),ha='right',va='top',fontsize=8,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.95,0.70,r\"$\\sigma_f$={:4.1f};  $\\sigma_o$={:4.1f}\".format(std_f,std_o),ha='right',va='top',fontsize=8,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.95,0.65,r\"N$_f$={};  N$_o$={}\".format(num_fcst_objs[ff],num_obs_objs[ff]),ha='right',va='top',fontsize=8,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.95,0.60,\"CRPS={:5.3f}\".format(pXX_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "               plt.title(\"{}Z Object 95th Percentile Value\".format(time_of_day), fontsize=10)\n",
    "               image_file = \"{}/{}_object_pXX_hist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "            # Pair interest\n",
    "            if False:\n",
    "               plt.figure(figsize=(5,5))\n",
    "               plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "               hist,bins = np.histogram(pair_interest,bins=np.arange(0.0,1.01,0.05))\n",
    "               plt.bar(bins[:-1],hist/float(len(pair_interest)),edgecolor='black',facecolor='red',width=0.05)\n",
    "               plt.xticks(np.arange(0.0,1.01,0.1))\n",
    "               plt.xlim(0,1)\n",
    "               plt.grid(linestyle=\":\",color='0.75')\n",
    "               plt.xlabel(\"Pair interest\",fontsize=10)\n",
    "               plt.ylabel(\"Relative frequency\",fontsize=10)\n",
    "               plt.tick_params(axis='both',labelsize=8)\n",
    "               mu_f = np.mean(pair_interest)\n",
    "               std_f = np.std(pair_interest)\n",
    "               med_f = np.median(pair_interest)\n",
    "               plt.figtext(0.93,0.88,r\"$\\mu$={:5.3f}\".format(mu_f),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.83,\"median={:5.3f}\".format(med_f),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.78,r\"$\\sigma$={:5.3f}\".format(std_f),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               plt.figtext(0.93,0.73,\"N={}\".format(len(pair_interest)),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "               image_file = \"{}/{}_pair_interest_dist_r{}t{}_{}Z.png\".format(img_dir,name,R,T,time_of_day)\n",
    "               plt.savefig(image_file,dpi=120)\n",
    "               plt.close()\n",
    "\n",
    "         # save intermediate calculations to npz files for later re-use\n",
    "         np.savez(\"{}/mode_metrics_r{}t{}_{}Z\".format(img_dir,R,T,time_of_day),OTS=OTS[ff],MMI=MMI[ff],POD=total_pod[ff],FAR=total_far[ff],SR=total_sr[ff],CSI=total_csi[ff],\n",
    "                  n_f_objs=num_fcst_objs[ff],n_o_objs=num_obs_objs[ff],area_crps=area_crps,length_crps=length_crps,width_crps=width_crps,aspect_crps=aspect_crps,\n",
    "                  complex_crps=complex_crps,pXX_crps=pXX_crps,lon_crps=cent_lon_crps,lat_crps=cent_lat_crps,ncases=n_cases,\n",
    "                  stm_mean_dist=mean_centroid_dist[ff,0],stm_med_dist=median_centroid_dist[ff,0],stm_std_dist=std_centroid_dist[ff,0],\n",
    "                  all_mean_dist=mean_centroid_dist[ff,1],all_med_dist=median_centroid_dist[ff,1],all_std_dist=std_centroid_dist[ff,1],fbias=fbias,\n",
    "                  gen_mean_dist=mean_centroid_dist[ff,2],gen_med_dist=median_centroid_dist[ff,2],gen_std_dist=std_centroid_dist[ff,2],\n",
    "                  MMI_flag=standard_MMI,agg_start_date=args.idate,agg_end_date=args.edate)\n",
    "\n",
    "         ff+=1 #increment independent loop counter so that numpy arrays can still be 0-indexed even if valid times do not start at 00Z\n",
    "\n",
    "      # END valid time loop\n",
    "\n",
    "      # Calculate final time-aggregated scores\n",
    "      for d in range(0,len(agg_vhr_start)):\n",
    "         if agg_hit[d] + agg_miss[d] > 0:\n",
    "            agg_pod[d] = float(agg_hit[d]) / (agg_hit[d] + agg_miss[d])\n",
    "         if agg_hit[d] + agg_fa[d] > 0:\n",
    "            agg_sr[d] = float(agg_hit[d]) / (agg_hit[d] + agg_fa[d])\n",
    "            agg_far[d] = float(agg_fa[d]) / (agg_hit[d] + agg_fa[d])\n",
    "         if agg_hit[d] + agg_fa[d] + agg_miss[d] > 0:\n",
    "            agg_csi[d] = float(agg_hit[d]) / (agg_hit[d] + agg_fa[d] + agg_miss[d])\n",
    "         agg_mean_dist[d] = agg_dist_sum[d] / agg_dist_count[d]\n",
    "         agg_OTS[d] = agg_ots_sum[d,0] / agg_ots_sum[d,1]\n",
    "         exec(\"agg_MMI[{:d}] = np.median(agg_max_int_{:02d})\".format(d,d))\n",
    "         # Save scores to file for later plotting\n",
    "         np.savez(\"{}/agg_scores_r{}t{}_{:02d}Z-{:02d}Z\".format(img_dir,R,T,agg_vhr_start[d],agg_vhr_end[d]),\n",
    "                  OTS=agg_OTS[d],MMI=agg_MMI[d],MMI_flag=standard_MMI,POD=agg_pod[d],FAR=agg_far[d],SR=agg_sr[d],CSI=agg_csi[d],\n",
    "                  NF=agg_fcst_count[d],NO=agg_obs_count[d],mean_dist=agg_mean_dist[d],gen_dist=agg_gen_dist[d],obj_fbias=agg_fbias[d])\n",
    "\n",
    "      # Sneak in plots of aggregated data\n",
    "      print(\"Making plots of time-aggregated spatial frequency bias\")\n",
    "      for d in range(0,len(agg_vhr_start)):\n",
    "         exec(\"f_hist2d,binx,biny = np.histogram2d(agg_f_cent_lon_{:02d},agg_f_cent_lat_{:02d},bins=[lon_bins,lat_bins])\".format(d,d))\n",
    "         exec(\"o_hist2d,binx,biny = np.histogram2d(agg_o_cent_lon_{:02d},agg_o_cent_lat_{:02d},bins=[lon_bins,lat_bins])\".format(d,d))\n",
    "         fbias_hist2d = np.ma.masked_where(o_hist2d == 0,f_hist2d/o_hist2d)\n",
    "         fig = plt.figure(figsize=figsize)\n",
    "         ax = plt.subplots_adjust(left=0.01,right=0.95,bottom=0.05,top=0.97)\n",
    "         m = Basemap(projection='lcc',width=proj_wid,height=proj_hgt,lat_0=clat,lon_0=clon,lat_1=38.5,resolution=res,area_thresh=min_area)\n",
    "         m.drawlsmask(land_color='0.9',ocean_color='powderblue')\n",
    "         m.drawcountries(linewidth=1,color='0.1')\n",
    "         if True:\n",
    "            m.drawcoastlines(linewidth=0.5,color='0.4')\n",
    "         else:\n",
    "            m.drawcounties(linewidth=0.5,color='0.6',linestyle='-')\n",
    "         m.drawstates(linewidth=0.5,color='0.5')\n",
    "         m.drawmapboundary(color=[0.25,0.01,0.02],linewidth=3)\n",
    "         m.drawmeridians(np.arange(-130.0,-50.1,5.0),linewidth=0.1,labels=[0,0,0,1],labelstyle='E/W',yoffset=lbl_off_y,fontsize=8,dashes=[2,2])\n",
    "         m.drawparallels(np.arange(20.0,55.1,5.0),linewidth=0.1,labels=[0,1,0,0],labelstyle='E/W',xoffset=lbl_off_x,fontsize=8,dashes=[2,2])\n",
    "         x2d,y2d = m(lons_2d,lats_2d)\n",
    "         fb_clevs_low = np.array([0,0.25,0.5,0.75,0.9])\n",
    "         fb_clevs_high = np.array([1.1,1.25,1.5,2,2.5,3,3.5,4])\n",
    "         fb_clevs = np.append(fb_clevs_low,fb_clevs_high)\n",
    "         cm_low = mplc.get_cmap('Oranges_r',len(fb_clevs_low))\n",
    "         cm_high = mplc.get_cmap('Purples',len(fb_clevs_high))\n",
    "         cmap = np.vstack((cm_low(np.linspace(0,1,len(fb_clevs_low)-1)),np.array([0.9,1.0,0.9,1.0]),cm_high(np.linspace(0,1,len(fb_clevs_high)))))\n",
    "         final_colors = ListedColormap(cmap)\n",
    "         norm = BoundaryNorm(boundaries=fb_clevs,ncolors=len(fb_clevs),clip=True)\n",
    "     #  plt.pcolormesh(x2d[:-1,:-1],y2d[:-1,:-1],fbias_hist2d,norm=norm,cmap=final_colors)\n",
    "         plt.contourf(x2d[:-1,:-1],y2d[:-1,:-1],fbias_hist2d,levels=fb_clevs,colors=cmap,extend='max')\n",
    "         cb = plt.colorbar(orientation='horizontal',fraction=0.05,aspect=50,pad=0.03,shrink=0.5,extend='max')\n",
    "         cb.set_ticks(fb_clevs) # Frequency bias plot\n",
    "         cb.set_label(r'Frequency bias ($N_f / N_o$)',fontsize=10)\n",
    "         cb.ax.tick_params(labelsize=8)\n",
    "         exec(\"_nf_ = len(agg_f_cent_lon_{:02d})\".format(d))\n",
    "       \t exec(\"_no_ = len(agg_o_cent_lon_{:02d})\".format(d))\n",
    "         min_sample = np.amin(o_hist2d)\n",
    "         med_sample = np.median(o_hist2d)\n",
    "         plt.figtext(0.75,0.22,r\"$N_f$={}\".format(_nf_) + \"\\n\" + r\"$N_o$={}\".format(_no_) + \"\\n\" + r\"median obs bin size = {:.0f}\".format(med_sample),\n",
    "                     ha='left',va='top',fontsize=10,fontweight=500,bbox=dict(facecolor='white',edgecolor='black',boxstyle='round,pad=0.3',linewidth=1.5))\n",
    "         image_file = \"{}/{}_centroid_fbias_heatmap_r{}t{}_{:02d}Z-{:02d}Z_{}.png\".format(img_dir,name,R,T,agg_vhr_start[d],agg_vhr_end[d],res_label)\n",
    "         fig.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "      # Make plots of all-24-hour object attributes\n",
    "      if True:\n",
    "         total_fcst_objs = np.sum(num_fcst_objs)\n",
    "         total_obs_objs = np.sum(num_obs_objs)\n",
    "         mass_crps = calc_CRPS(f_mass,o_mass,mass_bins)\n",
    "         area_crps = calc_CRPS(f_area,o_area,area_bins)\n",
    "         aspect_crps = calc_CRPS(f_aspect,o_aspect,np.arange(0.0,1.01,0.01))\n",
    "         complex_crps = calc_CRPS(f_complexity,o_complexity,np.arange(0.0,1.01,0.01))\n",
    "         pXX_crps = calc_CRPS(f_pXX,o_pXX,pXX_bins)\n",
    "\n",
    "         # Object area\n",
    "         plt.figure(figsize=(5,5))\n",
    "         plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.95)\n",
    "         f_hist,bin = np.histogram(dx**2*all_f_area,bins=area_bins)\n",
    "         o_hist,bin = np.histogram(dx**2*all_o_area,bins=area_bins)\n",
    "         plt.semilogx(0.5*(bin[:-1]+bin[1:]),f_hist/float(total_fcst_objs),'r-x',markersize=6,label=name)\n",
    "         plt.semilogx(0.5*(bin[:-1]+bin[1:]),o_hist/float(total_obs_objs),'k-x',markersize=6,label=\"MRMS\")\n",
    "         plt.grid(linestyle=\":\",color='0.75')\n",
    "         plt.xlabel(r\"Object area [km$^{2}$]\",size=8)\n",
    "         plt.ylabel(\"relative frequency\",size=8)\n",
    "         plt.tick_params(axis='both',labelsize=6)\n",
    "         plt.legend(loc=1,prop={'size':8})\n",
    "         mu_f = dx**2*np.mean(all_f_area)\n",
    "         mu_o = dx**2*np.mean(all_o_area)\n",
    "         std_f = np.std(dx**2*all_f_area)\n",
    "         std_o = np.std(dx**2*all_o_area)\n",
    "         med_f = dx**2*np.median(all_f_area)\n",
    "         med_o = dx**2*np.median(all_o_area)\n",
    "         plt.figtext(0.93,0.83,r\"$\\mu_f$={:4.0f};  $\\mu_o$={:4.0f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.78,r\"median$_f$={:4.0f};  median$_o$={:4.0f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.73,r\"$\\sigma_f$={:4.0f};  $\\sigma_o$={:4.0f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.68,r\"N$_f$={};  N$_o$={}\".format(total_fcst_objs,total_obs_objs),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.63,\"CRPS={:5.3f}\".format(area_crps),ha='right',va='top',fontweight='bold',fontsize=9,bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "         image_file = \"{}/{}_object_area_hist_r{}t{}_day.png\".format(img_dir,name,R,T)\n",
    "         plt.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "         # aspect ratio\n",
    "         plt.figure(figsize=(5,5))\n",
    "         plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.98)\n",
    "         f_hist,bin=np.histogram(all_f_aspect,bins=np.arange(0.0,1.01,0.05))\n",
    "         o_hist,bin=np.histogram(all_o_aspect,bins=np.arange(0.0,1.01,0.05))\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(total_fcst_objs),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(total_obs_objs),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "         plt.grid(linestyle=\":\",color='0.75')\n",
    "         plt.xlim(0,1)\n",
    "         plt.xlabel(\"Object aspect ratio [width/length]\",size=8)\n",
    "         plt.ylabel(\"relative frequency\",size=8)\n",
    "         plt.tick_params(axis='both',labelsize=6)\n",
    "         plt.legend(loc=1,prop={'size':8})\n",
    "         mu_f = np.mean(all_f_aspect)\n",
    "         mu_o = np.mean(all_o_aspect)\n",
    "         std_f = np.std(all_f_aspect)\n",
    "         std_o = np.std(all_o_aspect)\n",
    "         med_f = np.median(all_f_aspect)\n",
    "         med_o = np.median(all_o_aspect)\n",
    "         plt.figtext(0.14,0.97,r\"$\\mu_f$={:5.3f};  $\\mu_o$={:5.3f}\".format(mu_f,mu_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.14,0.92,r\"median$_f$={:5.3f};  median$_o$={:5.3f}\".format(med_f,med_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.14,0.87,r\"$\\sigma_f$={:5.3f};  $\\sigma_o$={:5.3f}\".format(std_f,std_o),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.14,0.82,r\"N$_f$={};  N$_o$={}\".format(total_fcst_objs,total_obs_objs),ha='left',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.14,0.77,\"CRPS={:5.3f}\".format(aspect_crps),ha='left',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "         image_file = \"{}/{}_object_aspect_hist_r{}t{}_day.png\".format(img_dir,name,R,T)\n",
    "         plt.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "         # complexity\n",
    "         plt.figure(figsize=(5,5))\n",
    "         plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.98)\n",
    "         f_hist,bin=np.histogram(all_f_complexity,bins=np.arange(0.0,1.01,0.05))\n",
    "         o_hist,bin=np.histogram(all_o_complexity,bins=np.arange(0.0,1.01,0.05))\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(total_fcst_objs),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(total_obs_objs),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "         plt.grid(linestyle=\":\",color='0.75')\n",
    "         plt.xlim(0,1)\n",
    "         plt.xlabel(\"Object complexity [-]\",size=8)\n",
    "         plt.ylabel(\"relative frequency\",size=8)\n",
    "         plt.tick_params(axis='both',labelsize=6)\n",
    "         plt.legend(loc=1,prop={'size':8})\n",
    "         mu_f = np.mean(all_f_complexity)\n",
    "         mu_o = np.mean(all_o_complexity)\n",
    "         std_f = np.std(all_f_complexity)\n",
    "         std_o = np.std(all_o_complexity)\n",
    "         med_f = np.median(all_f_complexity)\n",
    "         med_o = np.median(all_o_complexity)\n",
    "         plt.figtext(0.97,0.83,r\"$\\mu_f$={:5.3f};  $\\mu_o$={:5.3f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.78,r\"median$_f$={:5.3f};  median$_o$={:5.3f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.73,r\"$\\sigma_f$={:5.3f};  $\\sigma_o$={:5.3f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.68,r\"N$_f$={};  N$_o$={}\".format(total_fcst_objs,total_obs_objs),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.63,\"CRPS={:5.3f}\".format(complex_crps),ha='right',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "         image_file = \"{}/{}_object_complex_hist_r{}t{}_day.png\".format(img_dir,name,R,T)\n",
    "         plt.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "         # percentile intensity values\n",
    "         pbins = np.arange(0.0,100.1,5.0)\n",
    "         plt.figure(figsize=(5,5))\n",
    "         plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.98)\n",
    "         f_hist,bin=np.histogram(all_f_pXX,bins=pXX_bins)\n",
    "         o_hist,bin=np.histogram(all_o_pXX,bins=pXX_bins)\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),f_hist/float(total_fcst_objs),width=bin[1:]-bin[:-1],align='center',color='red',edgecolor='white',linewidth=1,label=name)\n",
    "         plt.bar(0.5*(bin[:-1]+bin[1:]),o_hist/float(total_obs_objs),width=1.0*(bin[1:]-bin[:-1]),align='center',color='None',edgecolor='black',linewidth=1,label=\"MRMS\")\n",
    "         plt.yscale('log')\n",
    "         plt.grid(linestyle=\":\",color='0.75')\n",
    "         if field == 'compref':\n",
    "            plt.xlabel(\"Object 95th percentile value\",size=8)\n",
    "         elif field == 'precip':\n",
    "            plt.xlabel(\"Object 99th percentile value\",size=8)\n",
    "         plt.ylabel(\"relative frequency\",size=8)\n",
    "         plt.tick_params(axis='both',labelsize=6)\n",
    "         plt.legend(loc=1,prop={'size':8})\n",
    "         mu_f = np.mean(all_f_pXX)\n",
    "         mu_o = np.mean(all_o_pXX)\n",
    "         std_f = np.std(all_f_pXX)\n",
    "         std_o = np.std(all_o_pXX)\n",
    "         med_f = np.median(all_f_pXX)\n",
    "         med_o = np.median(all_o_pXX)\n",
    "         plt.figtext(0.97,0.83,r\"$\\mu_f$={:4.1f};  $\\mu_o$={:4.1f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.78,r\"median$_f$={:4.1f};  median$_o$={:4.1f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.73,r\"$\\sigma_f$={:4.1f};  $\\sigma_o$={:4.1f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.97,0.68,r\"N$_f$={};  N$_o$={}\".format(total_fcst_objs,total_obs_objs),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.14,0.77,\"CRPS={:5.3f}\".format(pXX_crps),ha='left',va='top',fontsize=9,fontweight='bold',bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "         image_file = \"{}/{}_object_pXX_hist_r{}t{}_day.png\".format(img_dir,name,R,T)\n",
    "         plt.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "         # Object total mass\n",
    "         plt.figure(figsize=(5,5))\n",
    "         plt.subplots_adjust(left=0.125,bottom=0.1,top=0.98,right=0.95)\n",
    "         f_hist,bin = np.histogram(all_f_mass,bins=mass_bins)\n",
    "         o_hist,bin = np.histogram(all_o_mass,bins=mass_bins)\n",
    "         plt.semilogx(0.5*(bin[:-1]+bin[1:]),f_hist/float(total_fcst_objs),'r-x',ms=6,label=name)\n",
    "         plt.semilogx(0.5*(bin[:-1]+bin[1:]),o_hist/float(total_obs_objs),'k-x',ms=6,label=\"MRMS\")\n",
    "         plt.grid(linestyle=\":\",color='0.75')\n",
    "         plt.xlabel(r\"Object total mass (mm)\",size=8)\n",
    "         plt.ylabel(\"relative frequency\",size=8)\n",
    "         plt.tick_params(axis='both',labelsize=6)\n",
    "         plt.legend(loc=1,prop={'size':8})\n",
    "         mu_f = dx**2*np.mean(all_f_mass)\n",
    "         mu_o = dx**2*np.mean(all_o_mass)\n",
    "         std_f = np.std(dx**2*all_f_mass)\n",
    "         std_o = np.std(dx**2*all_o_mass)\n",
    "         med_f = dx**2*np.median(all_f_mass)\n",
    "         med_o = dx**2*np.median(all_o_mass)\n",
    "         plt.figtext(0.93,0.83,r\"$\\mu_f$={:4.0f};  $\\mu_o$={:4.0f}\".format(mu_f,mu_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.78,r\"median$_f$={:4.0f};  median$_o$={:4.0f}\".format(med_f,med_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.73,r\"$\\sigma_f$={:4.0f};  $\\sigma_o$={:4.0f}\".format(std_f,std_o),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.68,r\"N$_f$={};  N$_o$={}\".format(total_fcst_objs,total_obs_objs),ha='right',va='top',fontsize=7,bbox=dict(facecolor='white',edgecolor='black',linewidth=0.5))\n",
    "         plt.figtext(0.93,0.63,\"CRPS={:5.3f}\".format(mass_crps),ha='right',va='top',fontweight='bold',fontsize=9,bbox=dict(facecolor='white',edgecolor='black',linewidth=1))\n",
    "         image_file = \"{}/{}_object_mass_hist_r{}t{}_day.png\".format(img_dir,name,R,T)\n",
    "         plt.savefig(image_file,dpi=120)\n",
    "         plt.close()\n",
    "\n",
    "   # End convolution theshold loop\n",
    "# End convolution radii loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplc\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "# Defaults\n",
    "name = \"TOD_all\"\n",
    "field = \"compref\"\n",
    "img_dir = \"/mnt/lfs4/BMC/wrfruc/nickel/mode_img/\" + name + \"/\" + field + \"/images/valid_time\"\n",
    "data_root = \"/mnt/lfs4/BMC/wrfruc/nickel/mode_img/RRFS_CONUS_3km/compref/images/\" #+ name + \"/\" + field\n",
    "os.makedirs(img_dir, exist = True)\n",
    "# In case, for whatever reason, you wish to narrow the display of valid hours...\n",
    "ivhr = 0\n",
    "evhr = 23\n",
    "##### The above should generally always be 0 and 23\n",
    "nhrs = evhr - ivhr + 1\n",
    "thresh_mag = [25,30,35,40]\n",
    "units = 'dBZ'\n",
    "n_rad = 1\n",
    "n_thresh = len(thresh_mag)\n",
    "dx = 3.0 # grid spacing\n",
    "# create color scheme for multiple convolution radius and threshold testing\n",
    "cmp = mplc.get_cmap('coolwarm')\n",
    "nq = np.linspace(0,1,n_rad*n_thresh)\n",
    "colors = cmp(nq)\n",
    "whiter_colors = np.zeros_like(colors)\n",
    "for i in range(0,len(nq)):\n",
    "   whiter_colors[i,:] = 0.5*(colors[i,:] + 1.0)\n",
    "marks = ['o','^','D','s','+']\n",
    "lines = ['-','--','-.',':','']\n",
    "POD = np.zeros((n_rad,n_thresh,nhrs),dtype=np.float)\n",
    "SR = np.zeros((n_rad,n_thresh,nhrs),dtype=np.float)\n",
    "N_F = np.zeros(POD.shape,dtype=np.int)\n",
    "N_O = np.zeros(POD.shape,dtype=np.int)\n",
    "# The number of forecast cases is not (or should not, at least, be) a function of the convolution radius or threshold\n",
    "n_cases = np.zeros(nhrs,dtype=np.int)\n",
    "for vhr in range(ivhr,evhr+1):\n",
    "   number_of_cases_data = np.load('{}/mode_metrics_r1t1_{:02d}Z.npz'.format(data_root,vhr))\n",
    "   v = vhr - ivhr\n",
    "   n_cases[v] = number_of_cases_data['ncases']\n",
    "\n",
    "for R in range(1,n_rad+1):\n",
    "   for T in range(1,n_thresh+1):\n",
    "\n",
    "      if n_rad > 1:\n",
    "         plot_label = \"R{}-T{} {}\".format(R,thresh_mag[T-1],units)\n",
    "      else:\n",
    "         plot_label = \"{} {}\".format(thresh_mag[T-1],units)\n",
    "\n",
    "      color_number = n_thresh*(R-1) + T - 1\n",
    "      CSI = np.zeros(nhrs,dtype=np.float)\n",
    "      FAR = np.zeros(nhrs,dtype=np.float)\n",
    "      MMI = np.zeros(nhrs,dtype=np.float)\n",
    "      OTS = np.zeros(nhrs,dtype=np.float)\n",
    "      area_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      aspect_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      complex_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      length_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      width_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      p95_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      lat_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      lon_CRPS = np.zeros(nhrs,dtype=np.float)\n",
    "      obj_fbias = np.zeros(nhrs,dtype=np.float)\n",
    "      mean_dist_stm = np.zeros(nhrs,dtype=np.float)\n",
    "      med_dist_stm = np.zeros(nhrs,dtype=np.float)\n",
    "      std_dist_stm = np.zeros(nhrs,dtype=np.float)\n",
    "      mean_dist_all = np.zeros(nhrs,dtype=np.float)\n",
    "      med_dist_all = np.zeros(nhrs,dtype=np.float)\n",
    "      std_dist_all = np.zeros(nhrs,dtype=np.float)\n",
    "      mean_dist_gen = np.zeros(nhrs,dtype=np.float)\n",
    "      med_dist_gen = np.zeros(nhrs,dtype=np.float)\n",
    "      std_dist_gen = np.zeros(nhrs,dtype=np.float)\n",
    "\n",
    "      for vhr in range(ivhr,evhr+1):\n",
    "         v = vhr - ivhr\n",
    "         data = np.load('{}/mode_metrics_r{}t{}_{:02d}Z.npz'.format(data_root,R,T,vhr))\n",
    "\n",
    "         CSI[v] = data['CSI']\n",
    "       \t POD[R-1,T-1,v] = data['POD']\n",
    "       \t FAR[v] = data['FAR']\n",
    "       \t SR[R-1,T-1,v] = data['SR']\n",
    "       \t MMI[v] = data['MMI']\n",
    "       \t OTS[v] = data['OTS']\n",
    "         N_F[R-1,T-1,v] = data['n_f_objs']\n",
    "         N_O[R-1,T-1,v] = data['n_o_objs']\n",
    "         area_CRPS[v] = data['area_crps']\n",
    "       \t width_CRPS[v] = data['width_crps']\n",
    "       \t length_CRPS[v] = data['length_crps']\n",
    "       \t aspect_CRPS[v] = data['aspect_crps']\n",
    "       \t complex_CRPS[v] = data['complex_crps']\n",
    "       \t p95_CRPS[v] =\tdata['p95_crps']\n",
    "         lon_CRPS[v] = data['lon_crps']\n",
    "         lat_CRPS[v] = data['lat_crps']\n",
    "         obj_fbias[v] = data['fbias']\n",
    "         mean_dist_stm[v] = data['stm_mean_dist']\n",
    "         med_dist_stm[v] = data['stm_med_dist']\n",
    "         std_dist_stm[v] = data['stm_std_dist']\n",
    "         mean_dist_all[v] = data['all_mean_dist']\n",
    "         med_dist_all[v] = data['all_med_dist']\n",
    "         std_dist_all[v] = data['all_std_dist']\n",
    "         mean_dist_gen[v] = data['gen_mean_dist']\n",
    "         med_dist_gen[v] = data['gen_med_dist']\n",
    "         std_dist_gen[v] = data['gen_std_dist']\n",
    "         obj_fbias[v] = np.where(N_O[R-1,T-1,v] == 0.,np.nan,1.0*N_F[R-1,T-1,v]/N_O[R-1,T-1,v])\n",
    "\n",
    "      plt.figure(1,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.1,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),OTS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(2,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.1,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),MMI,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(6,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),area_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(7,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),width_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(8,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),length_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(9,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),aspect_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(10,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),complex_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(11,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),p95_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(12,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),lon_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(13,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.15,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),lat_CRPS,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(14,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.fill_between([ivhr,evhr],np.ones(2),[10.,10.],facecolor=[1.0,1.0,0.33,0.05],linestyle='None')\n",
    "      plt.fill_between([ivhr,evhr],[0.0,0.0],np.ones(2),facecolor=[0.75,0.37,1.0,0.05],linestyle='None')\n",
    "      t1 = plt.text(3,3.25,\"OVERFORECAST\",ha='left',va='top',color=[1.0,1.0,0.33],fontsize=12,fontweight=700,bbox=dict(facecolor='white',linewidth=2,edgecolor=[0.75,0.75,0.25],boxstyle='round,pad=0.5'))\n",
    "      t2 = plt.text(12,0.50,\"UNDERFORECAST\",ha='center',va='center',color=[0.75,0.37,1.0],fontsize=12,fontweight=700,bbox=dict(facecolor='white',linewidth=2,edgecolor=[0.56,0.278,0.75],boxstyle='round,pad=0.5'))\n",
    "      t1.set_path_effects([pe.Stroke(linewidth=2,foreground='0.25'),pe.Normal()])\n",
    "      t2.set_path_effects([pe.Stroke(linewidth=2,foreground='0.1'),pe.Normal()])\n",
    "      plt.plot([ivhr,evhr],[1.,1.],'k-',linewidth=2)\n",
    "      plt.plot(range(ivhr,evhr+1),obj_fbias,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      mean_dist_stm[mean_dist_stm == -999.] = np.nan\n",
    "      med_dist_stm[med_dist_stm == -999.] = np.nan\n",
    "      std_dist_stm[mean_dist_stm == -999.] = np.nan\n",
    "      mean_dist_all[mean_dist_all == -999.] = np.nan\n",
    "      med_dist_all[med_dist_all == -999.] = np.nan\n",
    "      std_dist_all[mean_dist_all == -999.] = np.nan\n",
    "      mean_dist_gen[mean_dist_gen == -999.] = np.nan\n",
    "      med_dist_gen[med_dist_gen == -999.] = np.nan\n",
    "      std_dist_gen[mean_dist_gen == -999.] = np.nan\n",
    "      plt.figure(15,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "#      plt.plot(range(ivhr,evhr+1),mean_dist_stm,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "      plt.errorbar(range(ivhr,evhr+1),mean_dist_stm,yerr=std_dist_stm,fmt='.-',markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(16,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),med_dist_stm,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(17,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),mean_dist_all,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(18,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),med_dist_all,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(19,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),mean_dist_gen,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(20,figsize=(6,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),med_dist_gen,linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(21,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.1,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),np.where(N_F[R-1,T-1,:] == 0,np.nan,1.*N_F[R-1,T-1,:]/n_cases),linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "      plt.figure(22,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.1,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),np.where(N_O[R-1,T-1,:] == 0,np.nan,1.*N_O[R-1,T-1,:]/n_cases),linestyle=lines[R-1],marker=marks[T-1],markersize=4,color=colors[color_number,:],label=plot_label)\n",
    "\n",
    "   # End convolution theshold loop\n",
    "# End convolution radii loop\n",
    "\n",
    "#print(\"Data range verified (YYYYMMDDHH of initialization): {} to {}\".format(data['agg_start_date'],data['agg_end_date']))\n",
    "\n",
    "# Make sure these lists correspond to each other and to the order of the plotting above\n",
    "if data['MMI_flag']:\n",
    "   MMI_title = \"MMI_std\"\n",
    "   MMI_name = \"standard MMI\"\n",
    "   print(\"Plotting standard MMI calculation\")\n",
    "else:\n",
    "   MMI_title = \"MMI_alt\"\n",
    "   MMI_name = \"alternate MMI\"\n",
    "   print(\"Plotting alternative MMI calculation\")\n",
    "\n",
    "fig_titles = [\"OTS\",MMI_title,\"\",\"\",\"\",\"CRPS_area\",\"CRPS_width\",\"CRPS_length\",\"CRPS_aspect\",\"CRPS_complex\",\"CRPS_p95\",\"CRPS_lon\",\"CRPS_lat\",\"object_fbias\",\n",
    "              \"mean_distance_stm\",\"median_distance_stm\",\"mean_distance_all\",\"median_distance_all\",\"mean_distance_gen\",\"median_distance_gen\",\"fcst_object_count\",\"obs_object_count\"]\n",
    "fig_y_axis = [\"OTS\",MMI_name,\"\",\"\",\"\",\n",
    "              \"area distribution CRPS\",\"width distribution CRPS\",\"length distribution CRPS\",\"aspect-ratio distribution CRPS\",\"complexity CRPS\",\"95th pct. distribution CRPS\",\"centroid longitude CRPS\",\"centroid latitude CRPS\",\n",
    "              r\"object frequency bias ($N_{f} / N_{o}$)\",\"mean distance between matched storm objects\",\"median distance between matched storm objects\",\"mean distance between matched objects\",\"median distance between matched objects\",\n",
    "              \"generalized mean distance between objects\",\"generalized median distance between objects\",\"average number of forecast objects per case\",\"average number of observation objects per case\"]\n",
    "for n in range(1,23):\n",
    " if n <= 2 or n >= 6:\n",
    "  plt.figure(n)\n",
    "  plt.grid(linestyle=\":\",color='0.75')\n",
    "  plt.xticks(range(0,24,3))\n",
    "  plt.xlim(ivhr-1,evhr+1)\n",
    "  if n <= 14:\n",
    "   if \"bias\" in fig_titles[n-1]:\n",
    "    plt.xlim(-0.5,23.5)\n",
    "    plt.yticks([0.0,0.5,0.75,0.9,1.0,1.1,1.25,1.5,2,2.5,3,3.5,4])\n",
    "    plt.ylim(0,3.5)\n",
    "   elif \"MMI\" in fig_titles[n-1]:\n",
    "    plt.yticks(np.arange(0.00,1.01,0.05))\n",
    "    plt.ylim(0.0,0.7)\n",
    "   elif \"OTS\" in fig_titles[n-1]:\n",
    "    plt.ylim(0.25,0.9)\n",
    "    plt.yticks(np.arange(0.25,0.91,0.05))\n",
    "  elif n >= 15 and n<= 20:\n",
    "   plt.ylim(0,60)\n",
    "  plt.xlabel(\"valid time (UTC)\",size=8)\n",
    "  plt.ylabel(fig_y_axis[n-1],size=8)\n",
    "  plt.tick_params(axis='both',labelsize=6)\n",
    "  plt.legend(loc=0,prop={'size':8},ncol=n_rad)\n",
    "  image_file = \"{}/{}_{}_{}.png\".format(img_dir,name,field,fig_titles[n-1])\n",
    "  plt.savefig(image_file,dpi=120)\n",
    "  plt.close(n)\n",
    "\n",
    "def performance_diagram_window(flag):\n",
    "# Settings to control the window of the performance diagram to be displayed\n",
    "   if flag:\n",
    "      plt.xlim(0,1)\n",
    "      plt.ylim(0,1)\n",
    "      plt.xticks(np.arange(0.0,1.01,0.1))\n",
    "      plt.yticks(np.arange(0.0,1.01,0.1))\n",
    "   else:\n",
    "      plt.xticks(np.arange(0.0,1.01,0.05))\n",
    "      plt.yticks(np.arange(0.0,1.01,0.05))\n",
    "      plt.xlim(0.2,0.7)\n",
    "      plt.ylim(0.5,0.9)\n",
    "\n",
    "# Roebber performance diagram containing ALL data\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.subplots_adjust(left=0.1,right=0.94,bottom=0.1,top=0.97)\n",
    "for csi in np.arange(0.1,0.91,0.1):\n",
    "   x = np.linspace(0.01,1.0,100)\n",
    "   y = np.zeros(x.shape,dtype=np.float)\n",
    "   for i in range(0,len(x)):\n",
    "      y[i] = 1.0 / (1/csi - 1/x[i] + 1)\n",
    "      if y[i] < 0.0 or y[i] > y[np.maximum(i-1,0)]:\n",
    "         y[i] = 1.0\n",
    "   plt.plot(x,y,'--',linewidth=0.5,color='0.7')\n",
    "   plt.text(x[95],y[95],\"{:3.1f}\".format(csi),fontsize=6,color='0.7',ha='center',va='center',bbox=dict(facecolor='white',edgecolor='None',pad=1))\n",
    "performance_diagram_window(False)\n",
    "for bias in [0.25,0.5,0.75,0.9,1.0,1.1,1.25,1.5,2,3,4,5]:\n",
    "   plt.plot([0,1],[0,bias],'-',linewidth=0.5,color='0.7')\n",
    "   if bias < 1.0:\n",
    "      plt.text(1.0,bias,\" {:4.2f}\".format(bias),fontsize=6,color='0.7',ha='left')\n",
    "   else:\n",
    "      plt.text(1.0/bias,1.0,\"{:4.2f}\".format(bias),fontsize=6,color='0.7',va='bottom')\n",
    "plt.plot([0,1],[0,1],'-',linewidth=1.5,color='0.3')\n",
    "for R in range(1,n_rad+1):\n",
    "   for T in range(1,n_thresh+1):\n",
    "      if n_rad > 1:\n",
    "         plot_label = \"R{}-T{} {}\".format(R,thresh_mag[T-1],units)\n",
    "      else:\n",
    "         plot_label = \"{} {}\".format(thresh_mag[T-1],units)\n",
    "      color_number = n_thresh*(R-1) + T - 1\n",
    "      plt.plot(SR[R-1,T-1,:],POD[R-1,T-1,:],marker=marks[T-1],markersize=4,mfc=colors[color_number],color=colors[color_number,:],label=plot_label)\n",
    "for R in range(1,n_rad+1):\n",
    "   for T in range(1,n_thresh+1):\n",
    "      color_number = n_thresh*(R-1) + T - 1\n",
    "      plt.plot(SR[R-1,T-1,0],POD[R-1,T-1,0],marker=marks[T-1],markersize=5,mfc='yellow',mew=0.5,mec='k')\n",
    "      plt.plot(SR[R-1,T-1,12],POD[R-1,T-1,12],marker=marks[T-1],markersize=5,mfc='orange',mew=0.5,mec='k')\n",
    "      plt.plot(SR[R-1,T-1,23],POD[R-1,T-1,23],marker=marks[T-1],markersize=5,mfc='sienna',mew=0.5,mec='k')\n",
    "plt.xlabel(\"success ratio (1-FAR)\",size=8)\n",
    "plt.ylabel(\"POD\",size=8)\n",
    "plt.tick_params(axis='both',labelsize=6)\n",
    "plt.legend(loc='lower right',prop={'size':8},ncol=1,fancybox=True)\n",
    "image_file = \"{}/{}_{}_object_performance_diagram_all.png\".format(img_dir,name,field)\n",
    "plt.savefig(image_file,dpi=120)\n",
    "plt.close()\n",
    "\n",
    "# Roebber performance diagram by valid hour\n",
    "for vhr in range(ivhr,evhr+1):\n",
    "   v = vhr - ivhr\n",
    "   plt.figure(6,figsize=(4,4))\n",
    "   plt.subplots_adjust(left=0.12,right=0.94,bottom=0.1,top=0.97)\n",
    "   for csi in np.arange(0.1,0.91,0.1):\n",
    "      x = np.linspace(0.01,1.0,100)\n",
    "      y = np.zeros(x.shape,dtype=np.float)\n",
    "      for i in range(0,len(x)):\n",
    "         y[i] = 1.0 / (1/csi - 1/x[i] + 1)\n",
    "         if y[i] < 0.0 or y[i] > y[np.maximum(i-1,0)]:\n",
    "            y[i] = 1.0\n",
    "      plt.plot(x,y,'--',linewidth=0.5,color='0.7')\n",
    "      plt.text(x[95],y[95],\"{:3.1f}\".format(csi),fontsize=6,color='0.7',ha='center',va='center',bbox=dict(facecolor='white',edgecolor='None',pad=1))\n",
    "   performance_diagram_window(True)\n",
    "   for bias in [0.25,0.5,0.75,0.9,1.0,1.1,1.25,1.5,2,3,4,5]:\n",
    "      plt.plot([0,1],[0,bias],'-',linewidth=0.5,color='0.7')\n",
    "      if bias < 1.0:\n",
    "         plt.text(1.0,bias,\" {:4.2f}\".format(bias),fontsize=6,color='0.7',ha='left')\n",
    "      else:\n",
    "         plt.text(1.0/bias,1.0,\"{:4.2f}\".format(bias),fontsize=6,color='0.7',va='bottom')\n",
    "   plt.plot([0,1],[0,1],'-',linewidth=1.5,color='0.3')\n",
    "   for R in range(1,n_rad+1):\n",
    "      for T in range(1,n_thresh+1):\n",
    "         if n_rad > 1:\n",
    "            plot_label = \"R{}-T{} {}\".format(R,thresh_mag[T-1],units)\n",
    "         else:\n",
    "            plot_label = \"{} {}\".format(thresh_mag[T-1],units)\n",
    "         color_number = n_thresh*(R-1) + T - 1\n",
    "         plt.plot(SR[R-1,T-1,v],POD[R-1,T-1,v],marker=marks[T-1],markersize=4,mfc=colors[color_number],color=colors[color_number,:],label=plot_label)\n",
    "   plt.xlabel(\"success ratio (1-FAR)\",size=8)\n",
    "   plt.ylabel(\"POD\",size=8)\n",
    "   plt.tick_params(axis='both',labelsize=6)\n",
    "   plt.legend(loc='lower right',prop={'size':8},ncol=1,fancybox=True)\n",
    "   image_file = \"{}/{}_{}_object_performance_diagram_{:02d}Z.png\".format(img_dir,name,field,vhr)\n",
    "   plt.savefig(image_file,dpi=120)\n",
    "   plt.close(6)\n",
    "\n",
    "# Roebber performance diagram by MODE configuration\n",
    "for R in range(1,n_rad+1):\n",
    "   for T in range(1,n_thresh+1):\n",
    "      color_number = n_thresh*(R-1) + T - 1\n",
    "      plt.figure(6,figsize=(4,4))\n",
    "      plt.subplots_adjust(left=0.12,right=0.94,bottom=0.1,top=0.97)\n",
    "      for csi in np.arange(0.1,0.91,0.1):\n",
    "         x = np.linspace(0.01,1.0,100)\n",
    "         y = np.zeros(x.shape,dtype=np.float)\n",
    "         for i in range(0,len(x)):\n",
    "            y[i] = 1.0 / (1/csi - 1/x[i] + 1)\n",
    "            if y[i] < 0.0 or y[i] > y[np.maximum(i-1,0)]:\n",
    "               y[i] = 1.0\n",
    "         plt.plot(x,y,'--',linewidth=0.5,color='0.7')\n",
    "         plt.text(x[95],y[95],\"{:3.1f}\".format(csi),fontsize=6,color='0.7',ha='center',va='center',bbox=dict(facecolor='white',edgecolor='None',pad=1))\n",
    "      performance_diagram_window(False)\n",
    "      for bias in [0.25,0.5,0.75,0.9,1.0,1.1,1.25,1.5,2,3,4,5]:\n",
    "         plt.plot([0,1],[0,bias],'-',linewidth=0.5,color='0.7')\n",
    "         if bias < 1.0:\n",
    "            plt.text(1.0,bias,\" {:4.2f}\".format(bias),fontsize=6,color='0.7',ha='left')\n",
    "         else:\n",
    "            plt.text(1.0/bias,1.0,\"{:4.2f}\".format(bias),fontsize=6,color='0.7',va='bottom')\n",
    "      plt.plot([0,1],[0,1],'-',linewidth=1.5,color='0.3')\n",
    "      plt.plot(SR[R-1,T-1,:],POD[R-1,T-1,:],marker=marks[T-1],linestyle='-',linewidth=0.5,markersize=4,mfc=colors[color_number],color=colors[color_number,:])\n",
    "      plt.text(SR[R-1,T-1,0]+0.01,POD[R-1,T-1,0]+0.01,\"{:02d}Z\".format(ivhr),fontsize=5,ha='left',va='baseline')\n",
    "      plt.text(SR[R-1,T-1,12-ivhr]+0.01,POD[R-1,T-1,12-ivhr]+0.01,\"{:02d}Z\".format(12),fontsize=5,ha='left',va='baseline')\n",
    "      plt.text(SR[R-1,T-1,evhr-ivhr]+0.01,POD[R-1,T-1,evhr-ivhr]+0.01,\"{:02d}Z\".format(evhr),fontsize=5,ha='left',va='baseline')\n",
    "      plt.xlabel(\"success ratio (1-FAR)\",size=8)\n",
    "      plt.ylabel(\"POD\",size=8)\n",
    "      plt.tick_params(axis='both',labelsize=6)\n",
    "      image_file = \"{}/{}_{}_object_performance_diagram_r{}t{}.png\".format(img_dir,name,field,R,T)\n",
    "      plt.savefig(image_file,dpi=120)\n",
    "      plt.close(6)\n",
    "\n",
    "      # Object counts\n",
    "      plt.figure(10,figsize=(5,5))\n",
    "      plt.subplots_adjust(left=0.125,right=0.98,bottom=0.1,top=0.98)\n",
    "      plt.plot(range(ivhr,evhr+1),N_F[R-1,T-1,:]/(1.*n_cases),'-x',linewidth=2,markersize=4,color=colors[color_number,:],label=name)\n",
    "      plt.plot(range(ivhr,evhr+1),N_O[R-1,T-1,:]/(1.*n_cases),'k-x',linewidth=3,markersize=4,label=\"MRMS\")\n",
    "      plt.xticks(range(0,37,3))\n",
    "      plt.grid(linestyle=\":\",color='0.75')\n",
    "      plt.xlim(ivhr-1,evhr+1)\n",
    "      plt.xlabel(\"Valid time (UTC)\",size=8)\n",
    "      plt.ylabel(\"Case-averaged object count\",size=8)\n",
    "      plt.tick_params(axis='both',labelsize=6)\n",
    "      plt.legend(loc=0,prop={'size':8})\n",
    "      image_file = \"{}/{}_{}_object_count_r{}t{}.png\".format(img_dir,name,field,R,T)\n",
    "      plt.savefig(image_file,dpi=120)\n",
    "      plt.close(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
